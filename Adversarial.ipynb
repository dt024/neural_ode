{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8f7cb222-3b87-48b6-bd9b-c9d0089db403",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "from torchdiffeq import odeint_adjoint as odeint\n",
    "from utils import *\n",
    "\n",
    "# CONSTANT \n",
    "device = \"cuda\"\n",
    "EPOCHS=1\n",
    "BATCH_SIZE=32\n",
    "IMG_SIZE=(32,32,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d4b49999-64bc-432d-b4d1-446f49860273",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "DIR = \"./data/mnist/\"\n",
    "MNIST = torchvision.datasets.MNIST(DIR,\n",
    "                                   train=True,\n",
    "                                   transform=None,\n",
    "                                   target_transform=None, download=True)\n",
    "\n",
    "\n",
    "#ds_len_, normal_ds_, pertubed_ds_ = preprocess_data(MNIST)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3b3ebc07-3063-4dcf-83d6-99d422be1ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_state_dict_parallel_convert(state_dict, mode):\n",
    "    from collections import OrderedDict\n",
    "    new_state_dict = OrderedDict()\n",
    "    if mode == 'to_single':\n",
    "        for k, v in state_dict.items():\n",
    "            name = k[7:]  # remove 'module.' of DataParallel\n",
    "            new_state_dict[name] = v\n",
    "    elif mode == 'to_parallel':\n",
    "        for k, v in state_dict.items():\n",
    "            name = 'module.' + k  # add 'module.' of DataParallel\n",
    "            new_state_dict[name] = v\n",
    "    elif mode == 'same':\n",
    "        new_state_dict = state_dict\n",
    "    else:\n",
    "        raise Exception('mode = to_single / to_parallel')\n",
    "\n",
    "    return new_state_dict \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "93e77ecf-2e0b-4081-b7bf-765b751026f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "\n",
    "loss_fn = torch.nn.functional.binary_cross_entropy_with_logits\n",
    "ode_func = ODEBlock().to(device)\n",
    "ode_model = ODENet(ode_func, device=device).to(device)\n",
    "ode_optimizer = torch.optim.Adam(ode_model.parameters(), lr=lr)\n",
    "cnn_model = Network().to(device)\n",
    "cnn_optimizer = torch.optim.Adam(cnn_model.parameters(), lr=lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1a3a0f74-9fec-454d-b5d9-4c79c78d644a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_state_dict = torch.load(\"./model/cnn_origin/mnist_original_origin.pt\",map_location=torch.device(device))\n",
    "cnn_state_dict = model_state_dict_parallel_convert(cnn_state_dict, mode=\"to_single\")\n",
    "cnn_model.load_state_dict(cnn_state_dict)\n",
    "ode_state_dict = torch.load(\"./model/ode_origin/mnist_original_origin.pt\",map_location=torch.device(device))\n",
    "ode_state_dict = model_state_dict_parallel_convert(ode_state_dict, mode=\"to_single\")\n",
    "ode_model.load_state_dict(ode_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7573caef-f627-4648-b539-7091a4bf6866",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FGSM attack code\n",
    "def fgsm_attack(image, epsilon, data_grad):\n",
    "    sign_data_grad = data_grad.sign()\n",
    "    perturbed_image = image + epsilon*sign_data_grad\n",
    "    # Adding clipping to maintain [0,1] range\n",
    "    perturbed_image = torch.clamp(perturbed_image, 0, 1)\n",
    "\n",
    "    return perturbed_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "688c195b-8d74-47b0-839e-d9ffdb2aea33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, device, test_loader, loss_fn, epsilon):\n",
    "    correct = 0\n",
    "    for data, target in test_loader:\n",
    "\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        data.requires_grad = True\n",
    "\n",
    "        # Forward pass the data through the model\n",
    "        outputs = model(data)\n",
    "        _, init_pred = torch.max(outputs, 1)\n",
    "        _, correct_labels = torch.max(target, 1)\n",
    "\n",
    "        # If the initial prediction is wrong, skip\n",
    "        if (init_pred == correct_labels).sum().item() != correct_labels.size():\n",
    "            continue\n",
    "\n",
    "        loss = loss_fn(outputs, correct_labels)\n",
    "        model.zero_grad()\n",
    "\n",
    "        loss.backward()\n",
    "        data_grad = data.grad.data\n",
    "        perturbed_data = fgsm_attack(data, epsilon, data_grad)\n",
    "\n",
    "        # Re-classify the perturbed image\n",
    "        output = model(perturbed_data)\n",
    "        _, final_pred = torch.max(outputs, 1)\n",
    "        if final_pred.item() == target.item():\n",
    "            correct += 1\n",
    "\n",
    "    final_acc = correct/float(len(test_loader))\n",
    "    print(\"Epsilon: {}\\tTest Accuracy = {} / {} = {}\".format(epsilon, correct, len(test_loader), final_acc))\n",
    "\n",
    "    \n",
    "    return final_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "469a29ad-12c9-40b9-a9df-3bc865438a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_fgsm_data(data, shape = (28,28), device=\"cpu\"):\n",
    "    X = []\n",
    "    Y = []\n",
    "    ds = {}\n",
    "    for data_idx, (x,y) in list(enumerate(data)):\n",
    "        X.append(np.array(x).reshape((1,shape[0],shape[0])))\n",
    "        Y.append(y)\n",
    "    y_data = F.one_hot(torch.Tensor(Y).to(torch.int64), num_classes=10)\n",
    "    y_data = y_data.to(device)\n",
    "    x_data = torch.Tensor(X)\n",
    "    x_data = x_data.to(device)\n",
    "    \n",
    "    ds.update({\"original\": TensorDataset(x_data / 255.0, y_data)})\n",
    "    ds_len = len(Y)\n",
    "    return ds_len, ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0d7d0d84-b2c3-4dc4-8d70-5f5adebca447",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ds_len, _ds = preprocess_fgsm_data(MNIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "67b2bf7d-c165-4022-b976-47131920a518",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_dis = 2000\n",
    "# train_set, val_set, _ = torch.utils.data.random_split(_ds['original'],data_dis)\n",
    "#print(type(train_set))\n",
    "# assert isinstance(train_set,torch.utils.data.Dataset)\n",
    "val_loader = DataLoader(_ds['original'], shuffle=True, batch_size=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "58ef55e8-484c-4857-b046-416ef3ea78f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epsilon: 0.3\tTest Accuracy = 0 / 60000 = 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(cnn_model, device, val_loader, loss_fn, 0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ebd7dd-a6c5-4753-8141-40b4f272623a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b501410-ff8e-464c-8a30-e135067bf15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "from torchdiffeq import odeint_adjoint as odeint\n",
    "# from jupyterthemes import jtplot\n",
    "# from neural_ode.utils import *\n",
    "# jtplot.style(theme=\"chesterish\")\n",
    " # CONSTANT \n",
    "device = \"cuda\"\n",
    "EPOCHS=1\n",
    "BATCH_SIZE=32\n",
    "IMG_SIZE=(32,32,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9fda2c3b-d3ec-4368-8d66-f5a4f97ba26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchdiffeq import odeint_adjoint as odeint\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# sys.path.insert(0,os.path.abspath(__file__))\n",
    "\n",
    "class ODEBlock(nn.Module):\n",
    "    def __init__(self, parallel=None):\n",
    "        super(ODEBlock,self).__init__()\n",
    "        self.parallel = parallel\n",
    "        self.conv1 = nn.Conv2d(64+1,64,3,1, padding=1)\n",
    "        self.norm1 = nn.GroupNorm(32,64)\n",
    "        self.relu  = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(64+1,64,3,1, padding=1)\n",
    "        self.norm2 = nn.GroupNorm(32,64)\n",
    "        \n",
    "    def forward(self,t,x): \n",
    "        tt = torch.ones_like(x[:, :1, :, :]) * t\n",
    "        out = torch.cat([tt, x], 1)\n",
    "        out = self.conv1(out)\n",
    "        out = self.norm1(out)\n",
    "        out = self.relu(out)\n",
    "        out = torch.cat([tt, out], 1)\n",
    "        out = self.conv2(out)\n",
    "        out = self.norm2(out)\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        return out\n",
    "     \n",
    "class ODENet(nn.Module):\n",
    "    def __init__(self, func, parallel=False, device=\"cpu\"):\n",
    "        super(ODENet, self).__init__()\n",
    "        assert isinstance(func, ODEBlock) or isinstance(func.module,ODEBlock), f\"argument function is not NeuralODEs model\"\n",
    "        self.fe = nn.Sequential(*[nn.Conv2d(3,64,3,1),\n",
    "                                  nn.GroupNorm(32,64),\n",
    "                                  nn.ReLU(),\n",
    "                                  # nn.Conv2d(64,64,3,1),\n",
    "                                  # nn.GroupNorm(32,64),\n",
    "                                  # nn.ReLU(),\n",
    "                                  nn.Conv2d(64,64,4,2),\n",
    "                                  nn.GroupNorm(32,64),\n",
    "                                  #1x64x12x12\n",
    "                                  nn.ReLU()])\n",
    "        self.rm = func\n",
    "        self.fcc = nn.Sequential(*[nn.AdaptiveAvgPool2d(1),\n",
    "                                   # 1 x 64 x 1 x 1\n",
    "                                   nn.Flatten(),\n",
    "                                   nn.Linear(64,10),\n",
    "                                   nn.Softmax()])\n",
    "        self.intergrated_time = torch.Tensor([0.,1.]).float().to(device)\n",
    "        self.parallel = parallel\n",
    "    def forward(self,x):\n",
    "        out = self.fe(x)\n",
    "        self.intergrated_time = self.intergrated_time.to(out.device)\n",
    "        if self.parallel:\n",
    "            out = odeint(self.rm.module, out, self.intergrated_time, method=\"euler\",options=dict(step_size=0.1), rtol=1e-3, atol=1e-3)[1]\n",
    "        else:\n",
    "            out = odeint(self.rm, out, self.intergrated_time, method=\"euler\",options=dict(step_size=0.1), rtol=1e-3, atol=1e-3)[1]\n",
    "        \n",
    "        #out = self.rm(out)\n",
    "        out = self.fcc(out)\n",
    "        return out\n",
    "    def evaluate(self, test_loader):\n",
    "        correct = 0\n",
    "        total = 0 \n",
    "        running_loss = 0\n",
    "        count = 0        \n",
    "        with torch.no_grad():\n",
    "            for batch_id , test_data in enumerate(test_loader,0):\n",
    "                count += 1\n",
    "                data, label = test_data\n",
    "                outputs = self.forward(data)\n",
    "                _, correct_labels = torch.max(label, 1) \n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += label.size(0)\n",
    "                correct += (predicted == correct_labels).sum().item()\n",
    "                running_loss += F.torch.nn.functional.binary_cross_entropy_with_logits(\n",
    "                    outputs.float(), label.float()).item()\n",
    "        #        print(f\"--> Total {total}\\n-->batch_id: {batch_id + 1}\")\n",
    "        acc = correct/total\n",
    "        running_loss /= count \n",
    "        return running_loss,acc\n",
    "\n",
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "        self.fe = nn.Sequential(*[\n",
    "            nn.Conv2d(3,64,3,1),\n",
    "            nn.GroupNorm(32,64),\n",
    "            nn.ReLU(),\n",
    "            # nn.Conv2d(64,64,3,1),\n",
    "            # nn.GroupNorm(32,64),\n",
    "            # nn.ReLU(),\n",
    "            nn.Conv2d(64,64,4,2),\n",
    "            nn.GroupNorm(32,64),\n",
    "            nn.ReLU()\n",
    "             \n",
    "        ])\n",
    "        self.rm = nn.Sequential(*[\n",
    "            nn.Conv2d(64,64,3,1, padding=1),\n",
    "            nn.GroupNorm(32,64),\n",
    "            nn.ReLU(), \n",
    "            nn.Conv2d(64,64,3,1, padding=1),\n",
    "            nn.GroupNorm(32,64),\n",
    "            nn.ReLU(),\n",
    "        ])\n",
    "        self.fcc = nn.Sequential(*[\n",
    "            #nn.Conv2d(64,1,3,1,padding=1),\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64,10),\n",
    "            nn.Softmax()\n",
    "        ])\n",
    "    def forward(self,x):\n",
    "        out = self.fe(x)\n",
    "        out = out + self.rm(out)\n",
    "        out = self.fcc(out)\n",
    "        return out\n",
    "\n",
    "        return self.net(x)\n",
    "    def evaluate(self, test_loader):\n",
    "        correct = 0\n",
    "        total = 0 \n",
    "        running_loss = 0\n",
    "        count = 0 \n",
    "        with torch.no_grad():\n",
    "            for test_data in test_loader:\n",
    "                count += 1\n",
    "                data, label = test_data\n",
    "                outputs = self.forward(data)\n",
    "                _, correct_labels = torch.max(label, 1) \n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += label.size(0)\n",
    "                correct += (predicted == correct_labels).sum().item()\n",
    "                running_loss += F.torch.nn.functional.binary_cross_entropy_with_logits(\n",
    "                    outputs.float(), label.float()).item()\n",
    "        acc = correct / total\n",
    "        running_loss /= count\n",
    "        \n",
    "        return running_loss,acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1eb9d669-029b-472b-b150-d6bd99952f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, optimizer, train_loader, val_loader,loss_fn, lr_scheduler=None, epochs=100, parallel=None):\n",
    "    #print(model.eval())\n",
    "    model.train()\n",
    "    print(f\"Numbers of parameters in model: {sum(p.numel() for p in model.parameters() if p.requires_grad)}\")\n",
    "    best_model, best_acc, best_epoch = None, 0, 0\n",
    "    history = {\"loss\": [], \"acc\": [], \"val_loss\": [], \"val_acc\": []}\n",
    "    for epoch_id in tqdm(range(epochs)):\n",
    "        total = 0\n",
    "        correct = 0\n",
    "        running_loss = 0\n",
    "        print(f\"Start epoch number: {epoch_id + 1}\")\n",
    "#        print(next(enumerate(train_loader,0)))\n",
    "        loads = list(enumerate(train_loader,0))\n",
    "        for batch_id, data in loads:\n",
    "#            print(\"Go here please\")\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            #print(f\"Start batch number: {batch_id + 1} in epoch number: {epoch_id + 1}\")\n",
    "            inputs, labels = data\n",
    "#            print(f\"This is labels: {labels}\\n\\n\\n\\n\")\n",
    "            #print(f\"Get data done\")\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            #print(f\"Reset the optimizer backward, grad to 0\") \n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs)\n",
    "            #print(f\"forward data through model\")\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            #print(f\"Get predicted class\")\n",
    "            _, correct_labels = torch.max(labels, 1)\n",
    "            #print(f\"Get label class\")\n",
    "            #print(labels)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == correct_labels).sum().item()\n",
    "            #print(\"Calculate the number of correct predictions\")\n",
    "            #print(labels.shape, outputs.shape)\n",
    "            loss = loss_fn(outputs.float(), labels.float())\n",
    "            loss.backward()\n",
    "            #print(\"Backward loss\")\n",
    "            optimizer.step()\n",
    "            #print(\"Step\")\n",
    "            running_loss += loss.item() \n",
    "            #print(\"End batch number: {batch_id + 1} in epoch number {epoch_id + 1}\")\n",
    "        #acc = round(correct/total * 1.0, 5)\n",
    "        if lr_scheduler is not None:\n",
    "            lr_scheduler.step()\n",
    "        acc = correct / total\n",
    "\n",
    "        #print(\"Accuracy was calculated\")\n",
    "        history[\"acc\"].append(acc)\n",
    "        history[\"loss\"].append(running_loss)\n",
    "        if parallel is not None:\n",
    "            val_loss, val_acc = model.module.evaluate(val_loader)\n",
    "        else:\n",
    "            val_loss, val_acc = model.evaluate(val_loader)\n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            best_epoch = epoch_id + 1\n",
    "            best_model = model\n",
    "        history[\"val_loss\"].append(val_loss)\n",
    "        history[\"val_acc\"].append(val_acc)\n",
    "        running_loss /= len(loads)\n",
    "        #print(f\"Epoch(s) {epoch_id + 1} | loss: {loss} | acc: {acc} | val_loss: {val_loss} | val_acc: {val_acc}\")\n",
    "        # checkpoint = {\n",
    "        #     'epoch': epoch_id + 1,\n",
    "        #     'model': model,\n",
    "        #     'best_epoch': best_epoch,\n",
    "        #     'optimizer': optimizer.state_dict()\n",
    "        # }\n",
    "        # torch.save(checkpoint, \"./checkpoints/checkpoint.pt\")\n",
    "        print(\"Epoch(s) {:04d}/{:04d} | acc: {:.05f} | loss: {:.09f} | val_acc: {:.05f} | val_loss: {:.09f} | Best epochs: {:04d} | Best acc: {:09f}\".format(\n",
    "            epoch_id + 1, epochs, acc, running_loss, val_acc, val_loss, best_epoch, best_acc\n",
    "            ))\n",
    "\n",
    "    return history, best_model, best_epoch, best_acc\n",
    "\n",
    "\n",
    "\n",
    "def main(ds_len, train_ds, valid_ds,model_type = \"ode\",data_name = \"mnist_50\",batch_size=32,epochs=100, lr=1e-3,train_num = 0, valid_num = 0, test_num = 0, weight_decay=None, device=\"cpu\", result_dir=\"./result\", model_dir=\"./model\", parallel=None):\n",
    "    print(f\"Number of train: {train_num}\\nNumber of validation: {valid_num}\")\n",
    "    #train_set = torch.utils.data.random_split(ds)\n",
    "    #print(type(train_set))\n",
    "    #assert isinstance(train_set,torch.utils.data.Dataset)\n",
    "    #train_ds, _ = torch.utils.data.random_split(train_ds, lengths=[TRAIN_NUM, ds_len - TRAIN_NUM])\n",
    "    #valid_ds, _ = torch.utils.data.random_split(valid_ds, lengths=[VALID_NUM, ds_len - VALID_NUM])\n",
    "    print(len(train_ds))\n",
    "    train_loader = DataLoader(train_ds, shuffle=True, batch_size=batch_size, drop_last=True)\n",
    "    val_loader  = DataLoader(valid_ds, shuffle=True, batch_size= batch_size * 16, drop_last=True)\n",
    "    loss_fn = torch.nn.functional.binary_cross_entropy_with_logits\n",
    "    if parallel is not None:\n",
    "        if model_type == \"ode\": \n",
    "            ode_func = ODEBlock(parallel=parallel)\n",
    "            ode_func = nn.DataParallel(ode_func).to(device)\n",
    "            model = ODENet(ode_func, parallel, device=device)\n",
    "            model = nn.DataParallel(model).to(device)\n",
    "#    ode_func = DDP(ODEBlock().to(device), output_device=device)\n",
    "#    ode_model = DDP(ODENet(ode_func,device=device).to(device),output_device=device)\n",
    "        elif model_type == \"cnn\":\n",
    "#            epochs= int(epochs * 1.5)\n",
    "            model = Network()\n",
    "            model = nn.DataParallel(model).to(device)\n",
    "    else:\n",
    "        if model_type == \"ode\": \n",
    "            ode_func = ODEBlock().to(device)\n",
    "            ode_func = ode_func.to(device)\n",
    "            model = ODENet(ode_func, device=device)\n",
    "            model = model.to(device)\n",
    "#    ode_func = DDP(ODEBlock().to(device), output_device=device)\n",
    "#    ode_model = DDP(ODENet(ode_func,device=device).to(device),output_device=device)\n",
    "        elif model_type == \"cnn\":\n",
    "            #epochs= int(epochs * 1.5)\n",
    "            model = Network().to(device)\n",
    "            #model = nn.DataParallel(model).to(device)\n",
    "        \n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "    lr_scheduler = None\n",
    "    if weight_decay is not None:\n",
    "        lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=weight_decay, patience=5)\n",
    "    his, model, epoch, acc = train_model(model, \n",
    "                      optimizer, \n",
    "                      train_loader,\n",
    "                      val_loader,\n",
    "                      lr_scheduler=lr_scheduler,\n",
    "                      loss_fn=loss_fn, \n",
    "                      epochs=epochs,\n",
    "                      parallel=parallel)\n",
    "     \n",
    "    # save_result(his,model_name=model_type,ds_name=data_name, result_dir=result_dir)\n",
    "    # if not os.path.exists(f\"{MODEL_DIR}/{model_type}_origin\"):\n",
    "    #     os.mkdir(f\"{MODEL_DIR}/{model_type}_origin\")\n",
    "    # print(\"Save original data modeling...\")\n",
    "    # torch.save(model.state_dict(), f\"{MODEL_DIR}/{model_type}_origin/{data_name}_origin.pt\" ) \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c72462f-4ed7-4129-ba4b-e18e3d9dd7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise(converted_data, sigma = 10,device=\"cpu\"):\n",
    "    pertubed_data = converted_data + torch.normal(torch.zeros(converted_data.shape),\n",
    "                                                  torch.ones(converted_data.shape) * sigma).to(device)\n",
    "    #pertubed_data = torch.tensor(random_noise(converted_data.cpu(), mode='gaussian', mean=0, var=sigma**2, clip=False)).float().to(device)\n",
    "    return pertubed_data\n",
    "def preprocess_data(data, shape = (28,28), sigma=None,device=\"cpu\", train=False):\n",
    "    if not train:\n",
    "        #assert type(sigma) == type(list()) or type(sigma) == type(None), f\"if train=False, the type(sigma) must be return a list object or NoneType object, but return {type(sigma)}\"\n",
    "        X = []\n",
    "        Y = []\n",
    "        ds = {}\n",
    "        sigma_noise = [50.,75.,100.]\n",
    "        for data_idx, (x,y) in list(enumerate(data)):\n",
    "            #X.append(np.array(x).reshape((3,shape[0],shape[0])))\n",
    "            X.append(np.array(x).transpose(2,0,1)) # Change the shape from (H,W,C) -> (C,H,W)\n",
    "            Y.append(y)\n",
    "        y_data = F.one_hot(torch.Tensor(Y).to(torch.int64), num_classes=10)\n",
    "        y_data = y_data.to(device)\n",
    "        x_data = torch.Tensor(X)\n",
    "        x_data = x_data.to(device)\n",
    "        if sigma:\n",
    "            x_noise_data = add_noise(x_data, sigma=sigma, device=device) / 255.0\n",
    "            print(f\"Generating {sigma}-pertubed-dataset\")\n",
    "        else:\n",
    "            x_noise_data = x_data\n",
    "            print(f\"Generating {sigma}-pertubed-dataset\")\n",
    "\n",
    "        pertubed_ds = TensorDataset(x_noise_data,y_data)\n",
    "        #ds.update({\"original\": TensorDataset(x_data / 255.0, y_data)})\n",
    "        ds_len = len(Y)\n",
    "        return ds_len, pertubed_ds\n",
    "    else:\n",
    "        import random\n",
    "        X = []\n",
    "        Y = []\n",
    "        for data_idx, (x, y) in list(enumerate(data)):\n",
    "            std = random.choice(sigma)\n",
    "            noise_x = (np.array(x) + np.random.normal(np.zeros_like(np.array(x)), np.ones_like(np.array(x)) * std))\n",
    "            X.append(noise_x.transpose(2,0,1))\n",
    "            Y.append(y)\n",
    "        y_data = F.one_hot(torch.Tensor(Y).to(torch.int64), num_classes=10)\n",
    "        y_data = y_data.to(device)\n",
    "        x_data = torch.Tensor(X)\n",
    "        x_data = x_data.to(device)\n",
    "        return len(Y), TensorDataset(x_data,y_data) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a436f411-a0e3-4eb5-8365-68ee98b84c10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Generating None-pertubed-dataset\n",
      "<class 'torch.utils.data.dataset.TensorDataset'>\n",
      "Generating None-pertubed-dataset\n",
      "Generating 1e-07-pertubed-dataset\n",
      "Generating 50.0-pertubed-dataset\n",
      "Generating 75.0-pertubed-dataset\n",
      "Generating 100.0-pertubed-dataset\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 128\n",
    "EPOCHS = 100\n",
    "TRAIN_NUM = VALID_NUM = TEST_NUM = 0\n",
    "MNIST = torchvision.datasets.CIFAR10('./data',\n",
    "                                   train=True,\n",
    "                                   transform=None,\n",
    "                                   target_transform=None, download=True)\n",
    "\n",
    "ds_len_, ds_ = preprocess_data(MNIST, sigma=None, device=device)\n",
    "ds_len_, pertubed_ds_ = preprocess_data(MNIST, sigma=[25.0,30.0,40.0], device=device, train=True)\n",
    "print(type(ds_))\n",
    "    \n",
    "sigma = [None, 1e-7, 50.0, 75.0, 100.0]\n",
    "loaders = [(key,DataLoader(preprocess_data(MNIST, sigma=key, device=device, train=False)[1], batch_size=12000)) for key in sigma]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e061880c-28cf-4e46-b72d-7c9a6806016c",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation = {\n",
    "    \"ode\": {\n",
    "        \n",
    "    },\n",
    "    \"cnn\": {\n",
    "\n",
    "    }\n",
    "}\n",
    "for k in sigma:\n",
    "    evaluation[\"ode\"].update({k: []})\n",
    "    evaluation[\"cnn\"].update({k: []})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89d7f8db-d9bb-4c7e-ac2c-b33d724d506e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "print(device)\n",
    "EPOCHS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f67d8c51-0602-4e8f-ad75-85c7513b8b57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train: 0\n",
      "Number of validation: 0\n",
      "50000\n",
      "Numbers of parameters in model: 142410\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efcc2e828f70485d953245c745a1cda9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start epoch number: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/administrator/anaconda3/envs/neural_ode/lib/python3.9/site-packages/torch/nn/modules/container.py:119: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch(s) 0001/0100 | acc: 0.27664 | loss: 0.724936743 | val_acc: 0.22618 | val_loss: 0.728563348 | Best epochs: 0001 | Best acc: 00.276643\n",
      "Start epoch number: 2\n",
      "Epoch(s) 0002/0100 | acc: 0.38704 | loss: 0.716102109 | val_acc: 0.28550 | val_loss: 0.724191554 | Best epochs: 0002 | Best acc: 00.387039\n",
      "Start epoch number: 3\n",
      "Epoch(s) 0003/0100 | acc: 0.44343 | loss: 0.710656770 | val_acc: 0.29159 | val_loss: 0.722991653 | Best epochs: 0003 | Best acc: 00.443429\n",
      "Start epoch number: 4\n",
      "Epoch(s) 0004/0100 | acc: 0.47316 | loss: 0.707569427 | val_acc: 0.39001 | val_loss: 0.714753484 | Best epochs: 0004 | Best acc: 00.473157\n",
      "Start epoch number: 5\n",
      "Epoch(s) 0005/0100 | acc: 0.50040 | loss: 0.704928773 | val_acc: 0.42460 | val_loss: 0.711437561 | Best epochs: 0005 | Best acc: 00.500401\n",
      "Start epoch number: 6\n",
      "Epoch(s) 0006/0100 | acc: 0.52310 | loss: 0.702952515 | val_acc: 0.36289 | val_loss: 0.717126384 | Best epochs: 0006 | Best acc: 00.523097\n",
      "Start epoch number: 7\n",
      "Epoch(s) 0007/0100 | acc: 0.54419 | loss: 0.700987595 | val_acc: 0.34772 | val_loss: 0.718765532 | Best epochs: 0007 | Best acc: 00.544191\n",
      "Start epoch number: 8\n",
      "Epoch(s) 0008/0100 | acc: 0.57226 | loss: 0.698588738 | val_acc: 0.36338 | val_loss: 0.716231210 | Best epochs: 0008 | Best acc: 00.572256\n",
      "Start epoch number: 9\n",
      "Epoch(s) 0009/0100 | acc: 0.58528 | loss: 0.697281864 | val_acc: 0.36648 | val_loss: 0.716487855 | Best epochs: 0009 | Best acc: 00.585276\n",
      "Start epoch number: 10\n",
      "Epoch(s) 0010/0100 | acc: 0.60447 | loss: 0.695530497 | val_acc: 0.37783 | val_loss: 0.715954721 | Best epochs: 0010 | Best acc: 00.604467\n",
      "Start epoch number: 11\n",
      "Epoch(s) 0011/0100 | acc: 0.61322 | loss: 0.694549044 | val_acc: 0.41777 | val_loss: 0.712036220 | Best epochs: 0011 | Best acc: 00.613221\n",
      "Start epoch number: 12\n",
      "Epoch(s) 0012/0100 | acc: 0.62933 | loss: 0.693114471 | val_acc: 0.43758 | val_loss: 0.710101883 | Best epochs: 0012 | Best acc: 00.629327\n",
      "Start epoch number: 13\n",
      "Epoch(s) 0013/0100 | acc: 0.64030 | loss: 0.692027483 | val_acc: 0.40788 | val_loss: 0.712631732 | Best epochs: 0013 | Best acc: 00.640304\n",
      "Start epoch number: 14\n",
      "Epoch(s) 0014/0100 | acc: 0.65435 | loss: 0.690797191 | val_acc: 0.40149 | val_loss: 0.713464881 | Best epochs: 0014 | Best acc: 00.654347\n",
      "Start epoch number: 15\n",
      "Epoch(s) 0015/0100 | acc: 0.66470 | loss: 0.689785020 | val_acc: 0.37382 | val_loss: 0.716640125 | Best epochs: 0015 | Best acc: 00.664704\n",
      "Start epoch number: 16\n",
      "Epoch(s) 0016/0100 | acc: 0.67504 | loss: 0.688774604 | val_acc: 0.38727 | val_loss: 0.714993646 | Best epochs: 0016 | Best acc: 00.675040\n",
      "Start epoch number: 17\n",
      "Epoch(s) 0017/0100 | acc: 0.67971 | loss: 0.688392191 | val_acc: 0.40755 | val_loss: 0.713189999 | Best epochs: 0017 | Best acc: 00.679708\n",
      "Start epoch number: 18\n",
      "Epoch(s) 0018/0100 | acc: 0.68976 | loss: 0.687375941 | val_acc: 0.31494 | val_loss: 0.721977656 | Best epochs: 0018 | Best acc: 00.689764\n",
      "Start epoch number: 19\n",
      "Epoch(s) 0019/0100 | acc: 0.69467 | loss: 0.687103753 | val_acc: 0.34176 | val_loss: 0.719101672 | Best epochs: 0019 | Best acc: 00.694671\n",
      "Start epoch number: 20\n",
      "Epoch(s) 0020/0100 | acc: 0.69726 | loss: 0.686696995 | val_acc: 0.32229 | val_loss: 0.720556316 | Best epochs: 0020 | Best acc: 00.697256\n",
      "Start epoch number: 21\n",
      "Epoch(s) 0021/0100 | acc: 0.70459 | loss: 0.685904735 | val_acc: 0.33639 | val_loss: 0.720501701 | Best epochs: 0021 | Best acc: 00.704587\n",
      "Start epoch number: 22\n",
      "Epoch(s) 0022/0100 | acc: 0.70990 | loss: 0.685526519 | val_acc: 0.39787 | val_loss: 0.714054212 | Best epochs: 0022 | Best acc: 00.709896\n",
      "Start epoch number: 23\n",
      "Epoch(s) 0023/0100 | acc: 0.71178 | loss: 0.685306199 | val_acc: 0.32526 | val_loss: 0.720525677 | Best epochs: 0023 | Best acc: 00.711779\n",
      "Start epoch number: 24\n",
      "Epoch(s) 0024/0100 | acc: 0.71681 | loss: 0.684811997 | val_acc: 0.29592 | val_loss: 0.723635599 | Best epochs: 0024 | Best acc: 00.716807\n",
      "Start epoch number: 25\n",
      "Epoch(s) 0025/0100 | acc: 0.72434 | loss: 0.684035592 | val_acc: 0.37960 | val_loss: 0.716361076 | Best epochs: 0025 | Best acc: 00.724339\n",
      "Start epoch number: 26\n",
      "Epoch(s) 0026/0100 | acc: 0.73057 | loss: 0.683639858 | val_acc: 0.27464 | val_loss: 0.725926583 | Best epochs: 0026 | Best acc: 00.730569\n",
      "Start epoch number: 27\n",
      "Epoch(s) 0027/0100 | acc: 0.73245 | loss: 0.683280185 | val_acc: 0.33970 | val_loss: 0.719870182 | Best epochs: 0027 | Best acc: 00.732452\n",
      "Start epoch number: 28\n",
      "Epoch(s) 0028/0100 | acc: 0.73794 | loss: 0.682840002 | val_acc: 0.38511 | val_loss: 0.715551359 | Best epochs: 0028 | Best acc: 00.737941\n",
      "Start epoch number: 29\n",
      "Epoch(s) 0029/0100 | acc: 0.74329 | loss: 0.682367622 | val_acc: 0.32391 | val_loss: 0.721209712 | Best epochs: 0029 | Best acc: 00.743289\n",
      "Start epoch number: 30\n",
      "Epoch(s) 0030/0100 | acc: 0.74383 | loss: 0.682330650 | val_acc: 0.27673 | val_loss: 0.726023960 | Best epochs: 0030 | Best acc: 00.743830\n",
      "Start epoch number: 31\n",
      "Epoch(s) 0031/0100 | acc: 0.74561 | loss: 0.682098547 | val_acc: 0.41241 | val_loss: 0.713039160 | Best epochs: 0031 | Best acc: 00.745613\n",
      "Start epoch number: 32\n",
      "Epoch(s) 0032/0100 | acc: 0.75433 | loss: 0.681393123 | val_acc: 0.22927 | val_loss: 0.730280903 | Best epochs: 0032 | Best acc: 00.754327\n",
      "Start epoch number: 33\n",
      "Epoch(s) 0033/0100 | acc: 0.75551 | loss: 0.681221156 | val_acc: 0.30975 | val_loss: 0.722465381 | Best epochs: 0033 | Best acc: 00.755509\n",
      "Start epoch number: 34\n",
      "Epoch(s) 0034/0100 | acc: 0.75885 | loss: 0.680937964 | val_acc: 0.36558 | val_loss: 0.717051846 | Best epochs: 0034 | Best acc: 00.758854\n",
      "Start epoch number: 35\n",
      "Epoch(s) 0035/0100 | acc: 0.76106 | loss: 0.680713345 | val_acc: 0.35488 | val_loss: 0.718128410 | Best epochs: 0035 | Best acc: 00.761058\n",
      "Start epoch number: 36\n",
      "Epoch(s) 0036/0100 | acc: 0.76655 | loss: 0.680240632 | val_acc: 0.38611 | val_loss: 0.715165456 | Best epochs: 0036 | Best acc: 00.766546\n",
      "Start epoch number: 37\n",
      "Epoch(s) 0037/0100 | acc: 0.76528 | loss: 0.680336567 | val_acc: 0.41178 | val_loss: 0.712443198 | Best epochs: 0036 | Best acc: 00.766546\n",
      "Start epoch number: 38\n",
      "Epoch(s) 0038/0100 | acc: 0.76647 | loss: 0.680103270 | val_acc: 0.35946 | val_loss: 0.717773696 | Best epochs: 0036 | Best acc: 00.766546\n",
      "Start epoch number: 39\n",
      "Epoch(s) 0039/0100 | acc: 0.77368 | loss: 0.679636696 | val_acc: 0.32424 | val_loss: 0.721266317 | Best epochs: 0039 | Best acc: 00.773678\n",
      "Start epoch number: 40\n",
      "Epoch(s) 0040/0100 | acc: 0.77358 | loss: 0.679678200 | val_acc: 0.30465 | val_loss: 0.723068898 | Best epochs: 0039 | Best acc: 00.773678\n",
      "Start epoch number: 41\n",
      "Epoch(s) 0041/0100 | acc: 0.77628 | loss: 0.679240460 | val_acc: 0.29936 | val_loss: 0.723810725 | Best epochs: 0041 | Best acc: 00.776282\n",
      "Start epoch number: 42\n",
      "Epoch(s) 0042/0100 | acc: 0.78103 | loss: 0.678825050 | val_acc: 0.39555 | val_loss: 0.714297387 | Best epochs: 0042 | Best acc: 00.781030\n",
      "Start epoch number: 43\n",
      "Epoch(s) 0043/0100 | acc: 0.78037 | loss: 0.678925615 | val_acc: 0.27641 | val_loss: 0.725856227 | Best epochs: 0042 | Best acc: 00.781030\n",
      "Start epoch number: 44\n",
      "Epoch(s) 0044/0100 | acc: 0.78425 | loss: 0.678588981 | val_acc: 0.29291 | val_loss: 0.724581167 | Best epochs: 0044 | Best acc: 00.784255\n",
      "Start epoch number: 45\n",
      "Epoch(s) 0045/0100 | acc: 0.78371 | loss: 0.678609242 | val_acc: 0.29268 | val_loss: 0.723226475 | Best epochs: 0044 | Best acc: 00.784255\n",
      "Start epoch number: 46\n",
      "Epoch(s) 0046/0100 | acc: 0.78427 | loss: 0.678452521 | val_acc: 0.29869 | val_loss: 0.723437158 | Best epochs: 0046 | Best acc: 00.784275\n",
      "Start epoch number: 47\n",
      "Epoch(s) 0047/0100 | acc: 0.79261 | loss: 0.677754713 | val_acc: 0.30296 | val_loss: 0.722921846 | Best epochs: 0047 | Best acc: 00.792608\n",
      "Start epoch number: 48\n",
      "Epoch(s) 0048/0100 | acc: 0.78732 | loss: 0.678266295 | val_acc: 0.32532 | val_loss: 0.720812269 | Best epochs: 0047 | Best acc: 00.792608\n",
      "Start epoch number: 49\n",
      "Epoch(s) 0049/0100 | acc: 0.79125 | loss: 0.677924939 | val_acc: 0.22864 | val_loss: 0.730471601 | Best epochs: 0047 | Best acc: 00.792608\n",
      "Start epoch number: 50\n",
      "Epoch(s) 0050/0100 | acc: 0.79245 | loss: 0.677711479 | val_acc: 0.30509 | val_loss: 0.722830504 | Best epochs: 0047 | Best acc: 00.792608\n",
      "Start epoch number: 51\n",
      "Epoch(s) 0051/0100 | acc: 0.79351 | loss: 0.677618496 | val_acc: 0.42063 | val_loss: 0.711854515 | Best epochs: 0051 | Best acc: 00.793510\n",
      "Start epoch number: 52\n",
      "Epoch(s) 0052/0100 | acc: 0.79643 | loss: 0.677532909 | val_acc: 0.30007 | val_loss: 0.723550518 | Best epochs: 0052 | Best acc: 00.796434\n",
      "Start epoch number: 53\n",
      "Epoch(s) 0053/0100 | acc: 0.79109 | loss: 0.677851995 | val_acc: 0.28493 | val_loss: 0.724863194 | Best epochs: 0052 | Best acc: 00.796434\n",
      "Start epoch number: 54\n",
      "Epoch(s) 0054/0100 | acc: 0.79497 | loss: 0.677524750 | val_acc: 0.25136 | val_loss: 0.728122264 | Best epochs: 0052 | Best acc: 00.796434\n",
      "Start epoch number: 55\n",
      "Epoch(s) 0055/0100 | acc: 0.79978 | loss: 0.677168685 | val_acc: 0.26849 | val_loss: 0.726270656 | Best epochs: 0055 | Best acc: 00.799780\n",
      "Start epoch number: 56\n",
      "Epoch(s) 0056/0100 | acc: 0.79489 | loss: 0.677484388 | val_acc: 0.27858 | val_loss: 0.725237129 | Best epochs: 0055 | Best acc: 00.799780\n",
      "Start epoch number: 57\n",
      "Epoch(s) 0057/0100 | acc: 0.80164 | loss: 0.676888477 | val_acc: 0.33948 | val_loss: 0.719864865 | Best epochs: 0057 | Best acc: 00.801643\n",
      "Start epoch number: 58\n",
      "Epoch(s) 0058/0100 | acc: 0.80220 | loss: 0.676859507 | val_acc: 0.30752 | val_loss: 0.722802900 | Best epochs: 0058 | Best acc: 00.802204\n",
      "Start epoch number: 59\n",
      "Epoch(s) 0059/0100 | acc: 0.80415 | loss: 0.676779327 | val_acc: 0.30656 | val_loss: 0.722229650 | Best epochs: 0059 | Best acc: 00.804147\n",
      "Start epoch number: 60\n",
      "Epoch(s) 0060/0100 | acc: 0.80098 | loss: 0.677011262 | val_acc: 0.30573 | val_loss: 0.722775077 | Best epochs: 0059 | Best acc: 00.804147\n",
      "Start epoch number: 61\n",
      "Epoch(s) 0061/0100 | acc: 0.80154 | loss: 0.676791190 | val_acc: 0.27966 | val_loss: 0.724691674 | Best epochs: 0059 | Best acc: 00.804147\n",
      "Start epoch number: 62\n",
      "Epoch(s) 0062/0100 | acc: 0.80441 | loss: 0.676767711 | val_acc: 0.33702 | val_loss: 0.720043312 | Best epochs: 0062 | Best acc: 00.804407\n",
      "Start epoch number: 63\n",
      "Epoch(s) 0063/0100 | acc: 0.80757 | loss: 0.676422530 | val_acc: 0.35280 | val_loss: 0.718190504 | Best epochs: 0063 | Best acc: 00.807572\n",
      "Start epoch number: 64\n",
      "Epoch(s) 0064/0100 | acc: 0.80903 | loss: 0.676281925 | val_acc: 0.34320 | val_loss: 0.718771937 | Best epochs: 0064 | Best acc: 00.809034\n",
      "Start epoch number: 65\n",
      "Epoch(s) 0065/0100 | acc: 0.80893 | loss: 0.676313811 | val_acc: 0.29012 | val_loss: 0.724537849 | Best epochs: 0064 | Best acc: 00.809034\n",
      "Start epoch number: 66\n",
      "Epoch(s) 0066/0100 | acc: 0.80691 | loss: 0.676454925 | val_acc: 0.29545 | val_loss: 0.723645583 | Best epochs: 0064 | Best acc: 00.809034\n",
      "Start epoch number: 67\n",
      "Epoch(s) 0067/0100 | acc: 0.80785 | loss: 0.676342985 | val_acc: 0.32210 | val_loss: 0.720999127 | Best epochs: 0064 | Best acc: 00.809034\n",
      "Start epoch number: 68\n",
      "Epoch(s) 0068/0100 | acc: 0.80940 | loss: 0.676064418 | val_acc: 0.34914 | val_loss: 0.718215346 | Best epochs: 0068 | Best acc: 00.809395\n",
      "Start epoch number: 69\n",
      "Epoch(s) 0069/0100 | acc: 0.81030 | loss: 0.676148215 | val_acc: 0.31781 | val_loss: 0.721766450 | Best epochs: 0069 | Best acc: 00.810296\n",
      "Start epoch number: 70\n",
      "Epoch(s) 0070/0100 | acc: 0.81510 | loss: 0.675690389 | val_acc: 0.23354 | val_loss: 0.730162675 | Best epochs: 0070 | Best acc: 00.815104\n",
      "Start epoch number: 71\n",
      "Epoch(s) 0071/0100 | acc: 0.81240 | loss: 0.675821069 | val_acc: 0.29510 | val_loss: 0.723438802 | Best epochs: 0070 | Best acc: 00.815104\n",
      "Start epoch number: 72\n",
      "Epoch(s) 0072/0100 | acc: 0.81502 | loss: 0.675700117 | val_acc: 0.30786 | val_loss: 0.722173574 | Best epochs: 0070 | Best acc: 00.815104\n",
      "Start epoch number: 73\n",
      "Epoch(s) 0073/0100 | acc: 0.81859 | loss: 0.675402414 | val_acc: 0.33594 | val_loss: 0.719813108 | Best epochs: 0073 | Best acc: 00.818590\n",
      "Start epoch number: 74\n",
      "Epoch(s) 0074/0100 | acc: 0.81450 | loss: 0.675584872 | val_acc: 0.39034 | val_loss: 0.714656735 | Best epochs: 0073 | Best acc: 00.818590\n",
      "Start epoch number: 75\n",
      "Epoch(s) 0075/0100 | acc: 0.81835 | loss: 0.675399533 | val_acc: 0.27681 | val_loss: 0.725204170 | Best epochs: 0073 | Best acc: 00.818590\n",
      "Start epoch number: 76\n",
      "Epoch(s) 0076/0100 | acc: 0.81931 | loss: 0.675358799 | val_acc: 0.29244 | val_loss: 0.723833077 | Best epochs: 0076 | Best acc: 00.819311\n",
      "Start epoch number: 77\n",
      "Epoch(s) 0077/0100 | acc: 0.82085 | loss: 0.675095923 | val_acc: 0.35592 | val_loss: 0.717473902 | Best epochs: 0077 | Best acc: 00.820853\n",
      "Start epoch number: 78\n",
      "Epoch(s) 0078/0100 | acc: 0.81969 | loss: 0.675195177 | val_acc: 0.21733 | val_loss: 0.731135746 | Best epochs: 0077 | Best acc: 00.820853\n",
      "Start epoch number: 79\n",
      "Epoch(s) 0079/0100 | acc: 0.81939 | loss: 0.675316938 | val_acc: 0.30914 | val_loss: 0.722613936 | Best epochs: 0077 | Best acc: 00.820853\n",
      "Start epoch number: 80\n",
      "Epoch(s) 0080/0100 | acc: 0.82081 | loss: 0.675080717 | val_acc: 0.25415 | val_loss: 0.727521578 | Best epochs: 0077 | Best acc: 00.820853\n",
      "Start epoch number: 81\n",
      "Epoch(s) 0081/0100 | acc: 0.81945 | loss: 0.675239393 | val_acc: 0.40340 | val_loss: 0.713622274 | Best epochs: 0077 | Best acc: 00.820853\n",
      "Start epoch number: 82\n",
      "Epoch(s) 0082/0100 | acc: 0.82330 | loss: 0.674893981 | val_acc: 0.26882 | val_loss: 0.726433006 | Best epochs: 0082 | Best acc: 00.823297\n",
      "Start epoch number: 83\n",
      "Epoch(s) 0083/0100 | acc: 0.82280 | loss: 0.675020987 | val_acc: 0.31189 | val_loss: 0.721963535 | Best epochs: 0082 | Best acc: 00.823297\n",
      "Start epoch number: 84\n",
      "Epoch(s) 0084/0100 | acc: 0.82362 | loss: 0.674874066 | val_acc: 0.26190 | val_loss: 0.726880339 | Best epochs: 0084 | Best acc: 00.823618\n",
      "Start epoch number: 85\n",
      "Epoch(s) 0085/0100 | acc: 0.82624 | loss: 0.674650904 | val_acc: 0.21985 | val_loss: 0.731532541 | Best epochs: 0085 | Best acc: 00.826242\n",
      "Start epoch number: 86\n",
      "Epoch(s) 0086/0100 | acc: 0.82668 | loss: 0.674634023 | val_acc: 0.24613 | val_loss: 0.728633886 | Best epochs: 0086 | Best acc: 00.826683\n",
      "Start epoch number: 87\n",
      "Epoch(s) 0087/0100 | acc: 0.82676 | loss: 0.674560672 | val_acc: 0.29392 | val_loss: 0.723907478 | Best epochs: 0087 | Best acc: 00.826763\n",
      "Start epoch number: 88\n",
      "Epoch(s) 0088/0100 | acc: 0.82238 | loss: 0.675018682 | val_acc: 0.26154 | val_loss: 0.727125073 | Best epochs: 0087 | Best acc: 00.826763\n",
      "Start epoch number: 89\n",
      "Epoch(s) 0089/0100 | acc: 0.82979 | loss: 0.674287995 | val_acc: 0.24469 | val_loss: 0.728975241 | Best epochs: 0089 | Best acc: 00.829788\n",
      "Start epoch number: 90\n",
      "Epoch(s) 0090/0100 | acc: 0.83189 | loss: 0.674142519 | val_acc: 0.27952 | val_loss: 0.725385929 | Best epochs: 0090 | Best acc: 00.831891\n",
      "Start epoch number: 91\n",
      "Epoch(s) 0091/0100 | acc: 0.82480 | loss: 0.674711851 | val_acc: 0.25749 | val_loss: 0.727669527 | Best epochs: 0090 | Best acc: 00.831891\n",
      "Start epoch number: 92\n",
      "Epoch(s) 0092/0100 | acc: 0.82907 | loss: 0.674402077 | val_acc: 0.39886 | val_loss: 0.713751530 | Best epochs: 0090 | Best acc: 00.831891\n",
      "Start epoch number: 93\n",
      "Epoch(s) 0093/0100 | acc: 0.82967 | loss: 0.674309524 | val_acc: 0.20321 | val_loss: 0.732914855 | Best epochs: 0090 | Best acc: 00.831891\n",
      "Start epoch number: 94\n",
      "Epoch(s) 0094/0100 | acc: 0.83019 | loss: 0.674254441 | val_acc: 0.24652 | val_loss: 0.728652634 | Best epochs: 0090 | Best acc: 00.831891\n",
      "Start epoch number: 95\n",
      "Epoch(s) 0095/0100 | acc: 0.82979 | loss: 0.674348979 | val_acc: 0.24396 | val_loss: 0.728867489 | Best epochs: 0090 | Best acc: 00.831891\n",
      "Start epoch number: 96\n",
      "Epoch(s) 0096/0100 | acc: 0.83069 | loss: 0.674245537 | val_acc: 0.24778 | val_loss: 0.728246269 | Best epochs: 0090 | Best acc: 00.831891\n",
      "Start epoch number: 97\n",
      "Epoch(s) 0097/0100 | acc: 0.82806 | loss: 0.674378549 | val_acc: 0.32945 | val_loss: 0.720395898 | Best epochs: 0090 | Best acc: 00.831891\n",
      "Start epoch number: 98\n",
      "Epoch(s) 0098/0100 | acc: 0.83233 | loss: 0.674110188 | val_acc: 0.28235 | val_loss: 0.725153108 | Best epochs: 0098 | Best acc: 00.832332\n",
      "Start epoch number: 99\n",
      "Epoch(s) 0099/0100 | acc: 0.83217 | loss: 0.674150547 | val_acc: 0.26379 | val_loss: 0.726492681 | Best epochs: 0098 | Best acc: 00.832332\n",
      "Start epoch number: 100\n",
      "Epoch(s) 0100/0100 | acc: 0.83566 | loss: 0.673798099 | val_acc: 0.23964 | val_loss: 0.729017369 | Best epochs: 0100 | Best acc: 00.835657\n",
      "Number of train: 0\n",
      "Number of validation: 0\n",
      "50000\n",
      "Numbers of parameters in model: 143562\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd3ce5a954e8484cba2826db424ebeea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start epoch number: 1\n",
      "Epoch(s) 0001/0100 | acc: 0.26492 | loss: 0.725372621 | val_acc: 0.23433 | val_loss: 0.726754526 | Best epochs: 0001 | Best acc: 00.264924\n",
      "Start epoch number: 2\n",
      "Epoch(s) 0002/0100 | acc: 0.35024 | loss: 0.718871609 | val_acc: 0.30302 | val_loss: 0.722948102 | Best epochs: 0002 | Best acc: 00.350240\n",
      "Start epoch number: 3\n",
      "Epoch(s) 0003/0100 | acc: 0.39609 | loss: 0.714957931 | val_acc: 0.22278 | val_loss: 0.727819997 | Best epochs: 0003 | Best acc: 00.396094\n",
      "Start epoch number: 4\n",
      "Epoch(s) 0004/0100 | acc: 0.44002 | loss: 0.710665456 | val_acc: 0.39701 | val_loss: 0.715234376 | Best epochs: 0004 | Best acc: 00.440024\n",
      "Start epoch number: 5\n",
      "Epoch(s) 0005/0100 | acc: 0.46264 | loss: 0.708463469 | val_acc: 0.36092 | val_loss: 0.717373741 | Best epochs: 0005 | Best acc: 00.462640\n",
      "Start epoch number: 6\n",
      "Epoch(s) 0006/0100 | acc: 0.48446 | loss: 0.706133474 | val_acc: 0.39823 | val_loss: 0.714412173 | Best epochs: 0006 | Best acc: 00.484455\n",
      "Start epoch number: 7\n",
      "Epoch(s) 0007/0100 | acc: 0.50204 | loss: 0.704603175 | val_acc: 0.41528 | val_loss: 0.712578771 | Best epochs: 0007 | Best acc: 00.502043\n",
      "Start epoch number: 8\n",
      "Epoch(s) 0008/0100 | acc: 0.52252 | loss: 0.702632352 | val_acc: 0.40605 | val_loss: 0.713308401 | Best epochs: 0008 | Best acc: 00.522516\n",
      "Start epoch number: 9\n",
      "Epoch(s) 0009/0100 | acc: 0.53716 | loss: 0.701352624 | val_acc: 0.32086 | val_loss: 0.721759290 | Best epochs: 0009 | Best acc: 00.537159\n",
      "Start epoch number: 10\n",
      "Epoch(s) 0010/0100 | acc: 0.54886 | loss: 0.700186318 | val_acc: 0.37701 | val_loss: 0.716511451 | Best epochs: 0010 | Best acc: 00.548858\n",
      "Start epoch number: 11\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_21567/966232578.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mcnn_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_len_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mds_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpertubed_ds_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"cnn\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf\"mnist_origin\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTRAIN_NUM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mVALID_NUM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTEST_NUM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparallel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mode_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_len_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mds_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpertubed_ds_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ode\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf\"mnist_origin\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTRAIN_NUM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mVALID_NUM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTEST_NUM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparallel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloaders\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnn_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataParallel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcnn_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcnn_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_21567/3488972562.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m(ds_len, train_ds, valid_ds, model_type, data_name, batch_size, epochs, lr, train_num, valid_num, test_num, weight_decay, device, result_dir, model_dir, parallel)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mweight_decay\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0mlr_scheduler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_scheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReduceLROnPlateau\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfactor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweight_decay\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m     his, model, epoch, acc = train_model(model, \n\u001b[0m\u001b[1;32m    120\u001b[0m                       \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m                       \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_21567/3488972562.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, optimizer, train_loader, val_loader, loss_fn, lr_scheduler, epochs, parallel)\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0;31m#print(labels.shape, outputs.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m             \u001b[0;31m#print(\"Backward loss\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/neural_ode/lib/python3.9/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/neural_ode/lib/python3.9/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    cnn_model = main(ds_len_,ds_, pertubed_ds_, device=device, model_type=\"cnn\", data_name=f\"mnist_origin\",batch_size=BATCH_SIZE, epochs=EPOCHS, train_num=TRAIN_NUM, valid_num=VALID_NUM, test_num=TEST_NUM, parallel=None) \n",
    "    ode_model = main(ds_len_,ds_, pertubed_ds_, device=device, model_type=\"ode\", data_name=f\"mnist_origin\",batch_size=BATCH_SIZE, epochs=EPOCHS, train_num=TRAIN_NUM, valid_num=VALID_NUM, test_num=TEST_NUM, parallel=None) \n",
    "    for k,l in loaders:\n",
    "        if isinstance(cnn_model, nn.DataParallel): cnn_model = cnn_model.module\n",
    "        if isinstance(ode_model, nn.DataParallel): ode_model = ode_model.module\n",
    "        _, cnn_acc = cnn_model.evaluate(l) \n",
    "        _, ode_acc = ode_model.evaluate(l) \n",
    "        \n",
    "        print(f\"CNNs for {k}-gaussian-pertubed CIFAR10 = {cnn_acc}\")\n",
    "        print(f\"ODEs for {k}-gaussian-pertubed CIFAR10 = {ode_acc}\")\n",
    "        \n",
    "\n",
    "        evaluation[\"ode\"][k].append(ode_acc)\n",
    "        evaluation[\"cnn\"][k].append(cnn_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f2001a2-6307-4295-922f-3dd2f1de9c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train: 0\n",
      "Number of validation: 0\n",
      "50000\n",
      "Numbers of parameters in model: 142410\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85e09bd097a940a2a7b6019fb2a86961",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start epoch number: 1\n",
      "Epoch(s) 0001/0100 | acc: 0.27839 | loss: 0.724676020 | val_acc: 0.30180 | val_loss: 0.723055390 | Best epochs: 0001 | Best acc: 00.278385\n",
      "Start epoch number: 2\n",
      "Epoch(s) 0002/0100 | acc: 0.38566 | loss: 0.716246858 | val_acc: 0.42969 | val_loss: 0.712295259 | Best epochs: 0002 | Best acc: 00.385657\n",
      "Start epoch number: 3\n",
      "Epoch(s) 0003/0100 | acc: 0.44507 | loss: 0.710588137 | val_acc: 0.49654 | val_loss: 0.706510117 | Best epochs: 0003 | Best acc: 00.445072\n",
      "Start epoch number: 4\n",
      "Epoch(s) 0004/0100 | acc: 0.47394 | loss: 0.707569284 | val_acc: 0.52057 | val_loss: 0.704074000 | Best epochs: 0004 | Best acc: 00.473938\n",
      "Start epoch number: 5\n",
      "Epoch(s) 0005/0100 | acc: 0.50541 | loss: 0.704674325 | val_acc: 0.53733 | val_loss: 0.701633309 | Best epochs: 0005 | Best acc: 00.505409\n",
      "Start epoch number: 6\n",
      "Epoch(s) 0006/0100 | acc: 0.52007 | loss: 0.703378335 | val_acc: 0.52541 | val_loss: 0.702912383 | Best epochs: 0006 | Best acc: 00.520072\n",
      "Start epoch number: 7\n",
      "Epoch(s) 0007/0100 | acc: 0.54002 | loss: 0.701375663 | val_acc: 0.56407 | val_loss: 0.699080497 | Best epochs: 0007 | Best acc: 00.540024\n",
      "Start epoch number: 8\n",
      "Epoch(s) 0008/0100 | acc: 0.55677 | loss: 0.699814459 | val_acc: 0.55408 | val_loss: 0.700377941 | Best epochs: 0008 | Best acc: 00.556771\n",
      "Start epoch number: 9\n",
      "Epoch(s) 0009/0100 | acc: 0.57784 | loss: 0.697907846 | val_acc: 0.57562 | val_loss: 0.698008915 | Best epochs: 0009 | Best acc: 00.577845\n",
      "Start epoch number: 10\n",
      "Epoch(s) 0010/0100 | acc: 0.58407 | loss: 0.697292452 | val_acc: 0.55280 | val_loss: 0.700042352 | Best epochs: 0010 | Best acc: 00.584075\n",
      "Start epoch number: 11\n",
      "Epoch(s) 0011/0100 | acc: 0.59890 | loss: 0.695892979 | val_acc: 0.62437 | val_loss: 0.693514677 | Best epochs: 0011 | Best acc: 00.598898\n",
      "Start epoch number: 12\n",
      "Epoch(s) 0012/0100 | acc: 0.61006 | loss: 0.694823278 | val_acc: 0.59015 | val_loss: 0.696410341 | Best epochs: 0012 | Best acc: 00.610056\n",
      "Start epoch number: 13\n",
      "Epoch(s) 0013/0100 | acc: 0.62382 | loss: 0.693627868 | val_acc: 0.65188 | val_loss: 0.691095752 | Best epochs: 0013 | Best acc: 00.623818\n",
      "Start epoch number: 14\n",
      "Epoch(s) 0014/0100 | acc: 0.63638 | loss: 0.692568624 | val_acc: 0.65521 | val_loss: 0.690589584 | Best epochs: 0014 | Best acc: 00.636378\n",
      "Start epoch number: 15\n",
      "Epoch(s) 0015/0100 | acc: 0.64679 | loss: 0.691451966 | val_acc: 0.63963 | val_loss: 0.692080932 | Best epochs: 0015 | Best acc: 00.646795\n",
      "Start epoch number: 16\n",
      "Epoch(s) 0016/0100 | acc: 0.65345 | loss: 0.690840115 | val_acc: 0.66764 | val_loss: 0.689519549 | Best epochs: 0016 | Best acc: 00.653446\n",
      "Start epoch number: 17\n",
      "Epoch(s) 0017/0100 | acc: 0.65415 | loss: 0.690669707 | val_acc: 0.67918 | val_loss: 0.688486929 | Best epochs: 0017 | Best acc: 00.654147\n",
      "Start epoch number: 18\n",
      "Epoch(s) 0018/0100 | acc: 0.66985 | loss: 0.689180461 | val_acc: 0.67454 | val_loss: 0.688718875 | Best epochs: 0018 | Best acc: 00.669852\n",
      "Start epoch number: 19\n",
      "Epoch(s) 0019/0100 | acc: 0.68131 | loss: 0.688373794 | val_acc: 0.69928 | val_loss: 0.686718717 | Best epochs: 0019 | Best acc: 00.681310\n",
      "Start epoch number: 20\n",
      "Epoch(s) 0020/0100 | acc: 0.68045 | loss: 0.688299285 | val_acc: 0.67574 | val_loss: 0.688958019 | Best epochs: 0019 | Best acc: 00.681310\n",
      "Start epoch number: 21\n",
      "Epoch(s) 0021/0100 | acc: 0.68784 | loss: 0.687472483 | val_acc: 0.71541 | val_loss: 0.685203304 | Best epochs: 0021 | Best acc: 00.687841\n",
      "Start epoch number: 22\n",
      "Epoch(s) 0022/0100 | acc: 0.69311 | loss: 0.687002218 | val_acc: 0.69523 | val_loss: 0.686935015 | Best epochs: 0022 | Best acc: 00.693109\n",
      "Start epoch number: 23\n",
      "Epoch(s) 0023/0100 | acc: 0.70208 | loss: 0.686115614 | val_acc: 0.70131 | val_loss: 0.686458357 | Best epochs: 0023 | Best acc: 00.702083\n",
      "Start epoch number: 24\n",
      "Epoch(s) 0024/0100 | acc: 0.70433 | loss: 0.686001172 | val_acc: 0.74512 | val_loss: 0.682443996 | Best epochs: 0024 | Best acc: 00.704327\n",
      "Start epoch number: 25\n",
      "Epoch(s) 0025/0100 | acc: 0.71328 | loss: 0.685165193 | val_acc: 0.72601 | val_loss: 0.684599742 | Best epochs: 0025 | Best acc: 00.713281\n",
      "Start epoch number: 26\n",
      "Epoch(s) 0026/0100 | acc: 0.71903 | loss: 0.684683361 | val_acc: 0.73100 | val_loss: 0.683578615 | Best epochs: 0026 | Best acc: 00.719030\n",
      "Start epoch number: 27\n",
      "Epoch(s) 0027/0100 | acc: 0.72242 | loss: 0.684365975 | val_acc: 0.74286 | val_loss: 0.682757812 | Best epochs: 0027 | Best acc: 00.722416\n",
      "Start epoch number: 28\n",
      "Epoch(s) 0028/0100 | acc: 0.72540 | loss: 0.684009085 | val_acc: 0.73704 | val_loss: 0.683184753 | Best epochs: 0028 | Best acc: 00.725401\n",
      "Start epoch number: 29\n",
      "Epoch(s) 0029/0100 | acc: 0.73181 | loss: 0.683497403 | val_acc: 0.75421 | val_loss: 0.681439787 | Best epochs: 0029 | Best acc: 00.731811\n",
      "Start epoch number: 30\n",
      "Epoch(s) 0030/0100 | acc: 0.73253 | loss: 0.683364198 | val_acc: 0.75755 | val_loss: 0.681046089 | Best epochs: 0030 | Best acc: 00.732532\n",
      "Start epoch number: 31\n",
      "Epoch(s) 0031/0100 | acc: 0.73994 | loss: 0.682773846 | val_acc: 0.73889 | val_loss: 0.683001891 | Best epochs: 0031 | Best acc: 00.739944\n",
      "Start epoch number: 32\n",
      "Epoch(s) 0032/0100 | acc: 0.74219 | loss: 0.682440313 | val_acc: 0.76070 | val_loss: 0.680812687 | Best epochs: 0032 | Best acc: 00.742188\n",
      "Start epoch number: 33\n",
      "Epoch(s) 0033/0100 | acc: 0.74623 | loss: 0.682149440 | val_acc: 0.76410 | val_loss: 0.680423836 | Best epochs: 0033 | Best acc: 00.746234\n",
      "Start epoch number: 34\n",
      "Epoch(s) 0034/0100 | acc: 0.75056 | loss: 0.681734615 | val_acc: 0.77877 | val_loss: 0.679492382 | Best epochs: 0034 | Best acc: 00.750561\n",
      "Start epoch number: 35\n",
      "Epoch(s) 0035/0100 | acc: 0.75112 | loss: 0.681722307 | val_acc: 0.78418 | val_loss: 0.678833179 | Best epochs: 0035 | Best acc: 00.751122\n",
      "Start epoch number: 36\n",
      "Epoch(s) 0036/0100 | acc: 0.75184 | loss: 0.681519146 | val_acc: 0.76215 | val_loss: 0.680723493 | Best epochs: 0036 | Best acc: 00.751843\n",
      "Start epoch number: 37\n",
      "Epoch(s) 0037/0100 | acc: 0.75741 | loss: 0.681084006 | val_acc: 0.77578 | val_loss: 0.679399299 | Best epochs: 0037 | Best acc: 00.757412\n",
      "Start epoch number: 38\n",
      "Epoch(s) 0038/0100 | acc: 0.75909 | loss: 0.681014398 | val_acc: 0.77476 | val_loss: 0.679372859 | Best epochs: 0038 | Best acc: 00.759095\n",
      "Start epoch number: 39\n",
      "Epoch(s) 0039/0100 | acc: 0.75865 | loss: 0.680956823 | val_acc: 0.78215 | val_loss: 0.678818541 | Best epochs: 0038 | Best acc: 00.759095\n",
      "Start epoch number: 40\n",
      "Epoch(s) 0040/0100 | acc: 0.75986 | loss: 0.680848504 | val_acc: 0.77356 | val_loss: 0.679699806 | Best epochs: 0040 | Best acc: 00.759856\n",
      "Start epoch number: 41\n",
      "Epoch(s) 0041/0100 | acc: 0.76573 | loss: 0.680340943 | val_acc: 0.77659 | val_loss: 0.679367177 | Best epochs: 0041 | Best acc: 00.765725\n",
      "Start epoch number: 42\n",
      "Epoch(s) 0042/0100 | acc: 0.76843 | loss: 0.680181846 | val_acc: 0.79169 | val_loss: 0.678014835 | Best epochs: 0042 | Best acc: 00.768429\n",
      "Start epoch number: 43\n",
      "Epoch(s) 0043/0100 | acc: 0.76931 | loss: 0.679961708 | val_acc: 0.77972 | val_loss: 0.679130152 | Best epochs: 0043 | Best acc: 00.769311\n",
      "Start epoch number: 44\n",
      "Epoch(s) 0044/0100 | acc: 0.77097 | loss: 0.679907786 | val_acc: 0.79124 | val_loss: 0.678039752 | Best epochs: 0044 | Best acc: 00.770974\n",
      "Start epoch number: 45\n",
      "Epoch(s) 0045/0100 | acc: 0.77017 | loss: 0.679899994 | val_acc: 0.76670 | val_loss: 0.679948802 | Best epochs: 0044 | Best acc: 00.770974\n",
      "Start epoch number: 46\n",
      "Epoch(s) 0046/0100 | acc: 0.78119 | loss: 0.678959075 | val_acc: 0.76318 | val_loss: 0.680433040 | Best epochs: 0046 | Best acc: 00.781190\n",
      "Start epoch number: 47\n",
      "Epoch(s) 0047/0100 | acc: 0.77796 | loss: 0.679151469 | val_acc: 0.78725 | val_loss: 0.678371807 | Best epochs: 0046 | Best acc: 00.781190\n",
      "Start epoch number: 48\n",
      "Epoch(s) 0048/0100 | acc: 0.77810 | loss: 0.679136813 | val_acc: 0.79053 | val_loss: 0.678031256 | Best epochs: 0046 | Best acc: 00.781190\n",
      "Start epoch number: 49\n",
      "Epoch(s) 0049/0100 | acc: 0.78151 | loss: 0.678832133 | val_acc: 0.79211 | val_loss: 0.678014033 | Best epochs: 0049 | Best acc: 00.781510\n",
      "Start epoch number: 50\n",
      "Epoch(s) 0050/0100 | acc: 0.77953 | loss: 0.678981028 | val_acc: 0.80324 | val_loss: 0.676814333 | Best epochs: 0049 | Best acc: 00.781510\n",
      "Start epoch number: 51\n",
      "Epoch(s) 0051/0100 | acc: 0.78622 | loss: 0.678389589 | val_acc: 0.81053 | val_loss: 0.676171417 | Best epochs: 0051 | Best acc: 00.786218\n",
      "Start epoch number: 52\n",
      "Epoch(s) 0052/0100 | acc: 0.78842 | loss: 0.678214414 | val_acc: 0.80817 | val_loss: 0.676341054 | Best epochs: 0052 | Best acc: 00.788421\n",
      "Start epoch number: 53\n",
      "Epoch(s) 0053/0100 | acc: 0.78976 | loss: 0.678040498 | val_acc: 0.78809 | val_loss: 0.678106772 | Best epochs: 0053 | Best acc: 00.789764\n",
      "Start epoch number: 54\n",
      "Epoch(s) 0054/0100 | acc: 0.79245 | loss: 0.677885625 | val_acc: 0.80908 | val_loss: 0.676538996 | Best epochs: 0054 | Best acc: 00.792448\n",
      "Start epoch number: 55\n",
      "Epoch(s) 0055/0100 | acc: 0.79251 | loss: 0.677770434 | val_acc: 0.78446 | val_loss: 0.678430977 | Best epochs: 0055 | Best acc: 00.792508\n",
      "Start epoch number: 56\n",
      "Epoch(s) 0056/0100 | acc: 0.78900 | loss: 0.678154633 | val_acc: 0.80554 | val_loss: 0.676519749 | Best epochs: 0055 | Best acc: 00.792508\n",
      "Start epoch number: 57\n",
      "Epoch(s) 0057/0100 | acc: 0.79631 | loss: 0.677463754 | val_acc: 0.80780 | val_loss: 0.676687740 | Best epochs: 0057 | Best acc: 00.796314\n",
      "Start epoch number: 58\n",
      "Epoch(s) 0058/0100 | acc: 0.79613 | loss: 0.677446457 | val_acc: 0.80328 | val_loss: 0.676928093 | Best epochs: 0057 | Best acc: 00.796314\n",
      "Start epoch number: 59\n",
      "Epoch(s) 0059/0100 | acc: 0.79728 | loss: 0.677298025 | val_acc: 0.80835 | val_loss: 0.676350112 | Best epochs: 0059 | Best acc: 00.797276\n",
      "Start epoch number: 60\n",
      "Epoch(s) 0060/0100 | acc: 0.79303 | loss: 0.677736707 | val_acc: 0.79598 | val_loss: 0.677333089 | Best epochs: 0059 | Best acc: 00.797276\n",
      "Start epoch number: 61\n",
      "Epoch(s) 0061/0100 | acc: 0.79928 | loss: 0.677250184 | val_acc: 0.82284 | val_loss: 0.675004231 | Best epochs: 0061 | Best acc: 00.799279\n",
      "Start epoch number: 62\n",
      "Epoch(s) 0062/0100 | acc: 0.79625 | loss: 0.677360520 | val_acc: 0.79869 | val_loss: 0.677213612 | Best epochs: 0061 | Best acc: 00.799279\n",
      "Start epoch number: 63\n",
      "Epoch(s) 0063/0100 | acc: 0.80441 | loss: 0.676800805 | val_acc: 0.80017 | val_loss: 0.677087898 | Best epochs: 0063 | Best acc: 00.804407\n",
      "Start epoch number: 64\n",
      "Epoch(s) 0064/0100 | acc: 0.80214 | loss: 0.676880654 | val_acc: 0.82092 | val_loss: 0.675160907 | Best epochs: 0063 | Best acc: 00.804407\n",
      "Start epoch number: 65\n",
      "Epoch(s) 0065/0100 | acc: 0.80321 | loss: 0.676811997 | val_acc: 0.82957 | val_loss: 0.674505380 | Best epochs: 0063 | Best acc: 00.804407\n",
      "Start epoch number: 66\n",
      "Epoch(s) 0066/0100 | acc: 0.80339 | loss: 0.676737961 | val_acc: 0.82444 | val_loss: 0.674962071 | Best epochs: 0063 | Best acc: 00.804407\n",
      "Start epoch number: 67\n",
      "Epoch(s) 0067/0100 | acc: 0.80809 | loss: 0.676513473 | val_acc: 0.82762 | val_loss: 0.674628491 | Best epochs: 0067 | Best acc: 00.808093\n",
      "Start epoch number: 68\n",
      "Epoch(s) 0068/0100 | acc: 0.80461 | loss: 0.676714021 | val_acc: 0.81875 | val_loss: 0.675573582 | Best epochs: 0067 | Best acc: 00.808093\n",
      "Start epoch number: 69\n",
      "Epoch(s) 0069/0100 | acc: 0.80224 | loss: 0.676799150 | val_acc: 0.82631 | val_loss: 0.674763774 | Best epochs: 0067 | Best acc: 00.808093\n",
      "Start epoch number: 70\n",
      "Epoch(s) 0070/0100 | acc: 0.80795 | loss: 0.676333021 | val_acc: 0.81917 | val_loss: 0.675399492 | Best epochs: 0067 | Best acc: 00.808093\n",
      "Start epoch number: 71\n",
      "Epoch(s) 0071/0100 | acc: 0.80972 | loss: 0.676156631 | val_acc: 0.81458 | val_loss: 0.675741874 | Best epochs: 0071 | Best acc: 00.809716\n",
      "Start epoch number: 72\n",
      "Epoch(s) 0072/0100 | acc: 0.81026 | loss: 0.676081252 | val_acc: 0.83124 | val_loss: 0.674307823 | Best epochs: 0072 | Best acc: 00.810256\n",
      "Start epoch number: 73\n",
      "Epoch(s) 0073/0100 | acc: 0.81262 | loss: 0.675942632 | val_acc: 0.80402 | val_loss: 0.676706232 | Best epochs: 0073 | Best acc: 00.812620\n",
      "Start epoch number: 74\n",
      "Epoch(s) 0074/0100 | acc: 0.81240 | loss: 0.675942923 | val_acc: 0.83441 | val_loss: 0.674024152 | Best epochs: 0073 | Best acc: 00.812620\n",
      "Start epoch number: 75\n",
      "Epoch(s) 0075/0100 | acc: 0.81558 | loss: 0.675590596 | val_acc: 0.83512 | val_loss: 0.674069015 | Best epochs: 0075 | Best acc: 00.815585\n",
      "Start epoch number: 76\n",
      "Epoch(s) 0076/0100 | acc: 0.81514 | loss: 0.675687770 | val_acc: 0.82721 | val_loss: 0.674789379 | Best epochs: 0075 | Best acc: 00.815585\n",
      "Start epoch number: 77\n",
      "Epoch(s) 0077/0100 | acc: 0.81605 | loss: 0.675570606 | val_acc: 0.83665 | val_loss: 0.673711893 | Best epochs: 0077 | Best acc: 00.816046\n",
      "Start epoch number: 78\n",
      "Epoch(s) 0078/0100 | acc: 0.81400 | loss: 0.675806363 | val_acc: 0.83818 | val_loss: 0.673466079 | Best epochs: 0077 | Best acc: 00.816046\n",
      "Start epoch number: 79\n",
      "Epoch(s) 0079/0100 | acc: 0.81362 | loss: 0.675822191 | val_acc: 0.83179 | val_loss: 0.674415576 | Best epochs: 0077 | Best acc: 00.816046\n",
      "Start epoch number: 80\n",
      "Epoch(s) 0080/0100 | acc: 0.81793 | loss: 0.675450256 | val_acc: 0.82052 | val_loss: 0.675210585 | Best epochs: 0080 | Best acc: 00.817929\n",
      "Start epoch number: 81\n",
      "Epoch(s) 0081/0100 | acc: 0.81715 | loss: 0.675527810 | val_acc: 0.82841 | val_loss: 0.674411868 | Best epochs: 0080 | Best acc: 00.817929\n",
      "Start epoch number: 82\n",
      "Epoch(s) 0082/0100 | acc: 0.81577 | loss: 0.675579090 | val_acc: 0.81651 | val_loss: 0.675565576 | Best epochs: 0080 | Best acc: 00.817929\n",
      "Start epoch number: 83\n",
      "Epoch(s) 0083/0100 | acc: 0.81761 | loss: 0.675474442 | val_acc: 0.84418 | val_loss: 0.673009115 | Best epochs: 0080 | Best acc: 00.817929\n",
      "Start epoch number: 84\n",
      "Epoch(s) 0084/0100 | acc: 0.82194 | loss: 0.674957836 | val_acc: 0.81114 | val_loss: 0.676060398 | Best epochs: 0084 | Best acc: 00.821935\n",
      "Start epoch number: 85\n",
      "Epoch(s) 0085/0100 | acc: 0.81953 | loss: 0.675199544 | val_acc: 0.82318 | val_loss: 0.675105646 | Best epochs: 0084 | Best acc: 00.821935\n",
      "Start epoch number: 86\n",
      "Epoch(s) 0086/0100 | acc: 0.81811 | loss: 0.675382491 | val_acc: 0.83569 | val_loss: 0.673832794 | Best epochs: 0084 | Best acc: 00.821935\n",
      "Start epoch number: 87\n",
      "Epoch(s) 0087/0100 | acc: 0.82075 | loss: 0.675086161 | val_acc: 0.81927 | val_loss: 0.675329909 | Best epochs: 0084 | Best acc: 00.821935\n",
      "Start epoch number: 88\n",
      "Epoch(s) 0088/0100 | acc: 0.82049 | loss: 0.675092052 | val_acc: 0.83653 | val_loss: 0.673792327 | Best epochs: 0084 | Best acc: 00.821935\n",
      "Start epoch number: 89\n",
      "Epoch(s) 0089/0100 | acc: 0.82288 | loss: 0.674938502 | val_acc: 0.83649 | val_loss: 0.673786509 | Best epochs: 0089 | Best acc: 00.822877\n",
      "Start epoch number: 90\n",
      "Epoch(s) 0090/0100 | acc: 0.82396 | loss: 0.674913564 | val_acc: 0.84580 | val_loss: 0.673018619 | Best epochs: 0090 | Best acc: 00.823958\n",
      "Start epoch number: 91\n",
      "Epoch(s) 0091/0100 | acc: 0.82250 | loss: 0.674951144 | val_acc: 0.83101 | val_loss: 0.673924255 | Best epochs: 0090 | Best acc: 00.823958\n",
      "Start epoch number: 92\n",
      "Epoch(s) 0092/0100 | acc: 0.82608 | loss: 0.674691417 | val_acc: 0.84664 | val_loss: 0.672714725 | Best epochs: 0092 | Best acc: 00.826082\n",
      "Start epoch number: 93\n",
      "Epoch(s) 0093/0100 | acc: 0.82564 | loss: 0.674714717 | val_acc: 0.82381 | val_loss: 0.674785979 | Best epochs: 0092 | Best acc: 00.826082\n",
      "Start epoch number: 94\n",
      "Epoch(s) 0094/0100 | acc: 0.82482 | loss: 0.674785338 | val_acc: 0.84878 | val_loss: 0.672563444 | Best epochs: 0092 | Best acc: 00.826082\n",
      "Start epoch number: 95\n",
      "Epoch(s) 0095/0100 | acc: 0.82889 | loss: 0.674471741 | val_acc: 0.80290 | val_loss: 0.676497519 | Best epochs: 0095 | Best acc: 00.828886\n",
      "Start epoch number: 96\n",
      "Epoch(s) 0096/0100 | acc: 0.82770 | loss: 0.674524891 | val_acc: 0.81156 | val_loss: 0.675775995 | Best epochs: 0095 | Best acc: 00.828886\n",
      "Start epoch number: 97\n",
      "Epoch(s) 0097/0100 | acc: 0.82861 | loss: 0.674473720 | val_acc: 0.84892 | val_loss: 0.672459374 | Best epochs: 0095 | Best acc: 00.828886\n",
      "Start epoch number: 98\n",
      "Epoch(s) 0098/0100 | acc: 0.82917 | loss: 0.674265096 | val_acc: 0.84188 | val_loss: 0.673276688 | Best epochs: 0098 | Best acc: 00.829167\n",
      "Start epoch number: 99\n",
      "Epoch(s) 0099/0100 | acc: 0.82406 | loss: 0.674767930 | val_acc: 0.81557 | val_loss: 0.675381305 | Best epochs: 0098 | Best acc: 00.829167\n",
      "Start epoch number: 100\n",
      "Epoch(s) 0100/0100 | acc: 0.82790 | loss: 0.674389515 | val_acc: 0.82760 | val_loss: 0.674560634 | Best epochs: 0098 | Best acc: 00.829167\n",
      "Number of train: 0\n",
      "Number of validation: 0\n",
      "50000\n",
      "Numbers of parameters in model: 143562\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4af80b02b33847efa6bb473ce02a7692",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start epoch number: 1\n",
      "Epoch(s) 0001/0100 | acc: 0.26148 | loss: 0.725745368 | val_acc: 0.32961 | val_loss: 0.720841157 | Best epochs: 0001 | Best acc: 00.261478\n",
      "Start epoch number: 2\n",
      "Epoch(s) 0002/0100 | acc: 0.35284 | loss: 0.718657690 | val_acc: 0.38639 | val_loss: 0.715924082 | Best epochs: 0002 | Best acc: 00.352845\n",
      "Start epoch number: 3\n",
      "Epoch(s) 0003/0100 | acc: 0.39762 | loss: 0.714524307 | val_acc: 0.44242 | val_loss: 0.711367168 | Best epochs: 0003 | Best acc: 00.397616\n",
      "Start epoch number: 4\n",
      "Epoch(s) 0004/0100 | acc: 0.43215 | loss: 0.711247290 | val_acc: 0.43481 | val_loss: 0.710580808 | Best epochs: 0004 | Best acc: 00.432151\n",
      "Start epoch number: 5\n",
      "Epoch(s) 0005/0100 | acc: 0.46637 | loss: 0.708067402 | val_acc: 0.48749 | val_loss: 0.706607848 | Best epochs: 0005 | Best acc: 00.466366\n",
      "Start epoch number: 6\n",
      "Epoch(s) 0006/0100 | acc: 0.48608 | loss: 0.706357270 | val_acc: 0.50120 | val_loss: 0.705515613 | Best epochs: 0006 | Best acc: 00.486078\n",
      "Start epoch number: 7\n",
      "Epoch(s) 0007/0100 | acc: 0.50731 | loss: 0.704145222 | val_acc: 0.51084 | val_loss: 0.703575129 | Best epochs: 0007 | Best acc: 00.507312\n",
      "Start epoch number: 8\n",
      "Epoch(s) 0008/0100 | acc: 0.52756 | loss: 0.702321749 | val_acc: 0.54156 | val_loss: 0.700790259 | Best epochs: 0008 | Best acc: 00.527564\n",
      "Start epoch number: 9\n",
      "Epoch(s) 0009/0100 | acc: 0.53514 | loss: 0.701571277 | val_acc: 0.49994 | val_loss: 0.704366187 | Best epochs: 0009 | Best acc: 00.535136\n",
      "Start epoch number: 10\n",
      "Epoch(s) 0010/0100 | acc: 0.54002 | loss: 0.701069284 | val_acc: 0.54378 | val_loss: 0.700901113 | Best epochs: 0010 | Best acc: 00.540024\n",
      "Start epoch number: 11\n",
      "Epoch(s) 0011/0100 | acc: 0.55723 | loss: 0.699391006 | val_acc: 0.58175 | val_loss: 0.697281338 | Best epochs: 0011 | Best acc: 00.557232\n",
      "Start epoch number: 12\n",
      "Epoch(s) 0012/0100 | acc: 0.57626 | loss: 0.697702626 | val_acc: 0.59819 | val_loss: 0.695697154 | Best epochs: 0012 | Best acc: 00.576262\n",
      "Start epoch number: 13\n",
      "Epoch(s) 0013/0100 | acc: 0.57364 | loss: 0.697689402 | val_acc: 0.58555 | val_loss: 0.696690475 | Best epochs: 0012 | Best acc: 00.576262\n",
      "Start epoch number: 14\n",
      "Epoch(s) 0014/0100 | acc: 0.58556 | loss: 0.696708702 | val_acc: 0.54661 | val_loss: 0.700247906 | Best epochs: 0014 | Best acc: 00.585557\n",
      "Start epoch number: 15\n",
      "Epoch(s) 0015/0100 | acc: 0.58476 | loss: 0.696760212 | val_acc: 0.62567 | val_loss: 0.693004134 | Best epochs: 0014 | Best acc: 00.585557\n",
      "Start epoch number: 16\n",
      "Epoch(s) 0016/0100 | acc: 0.59355 | loss: 0.696021354 | val_acc: 0.59294 | val_loss: 0.695886413 | Best epochs: 0016 | Best acc: 00.593550\n",
      "Start epoch number: 17\n",
      "Epoch(s) 0017/0100 | acc: 0.59641 | loss: 0.695650837 | val_acc: 0.63595 | val_loss: 0.692205543 | Best epochs: 0017 | Best acc: 00.596414\n",
      "Start epoch number: 18\n",
      "Epoch(s) 0018/0100 | acc: 0.60811 | loss: 0.694569218 | val_acc: 0.63975 | val_loss: 0.691574134 | Best epochs: 0018 | Best acc: 00.608113\n",
      "Start epoch number: 19\n",
      "Epoch(s) 0019/0100 | acc: 0.60725 | loss: 0.694536431 | val_acc: 0.61121 | val_loss: 0.694210192 | Best epochs: 0018 | Best acc: 00.608113\n",
      "Start epoch number: 20\n",
      "Epoch(s) 0020/0100 | acc: 0.61362 | loss: 0.693908283 | val_acc: 0.62919 | val_loss: 0.692677779 | Best epochs: 0020 | Best acc: 00.613622\n",
      "Start epoch number: 21\n",
      "Epoch(s) 0021/0100 | acc: 0.61859 | loss: 0.693544961 | val_acc: 0.59973 | val_loss: 0.694971420 | Best epochs: 0021 | Best acc: 00.618590\n",
      "Start epoch number: 22\n",
      "Epoch(s) 0022/0100 | acc: 0.61949 | loss: 0.693330989 | val_acc: 0.63798 | val_loss: 0.691898281 | Best epochs: 0022 | Best acc: 00.619491\n",
      "Start epoch number: 23\n",
      "Epoch(s) 0023/0100 | acc: 0.61424 | loss: 0.693925617 | val_acc: 0.59888 | val_loss: 0.695476286 | Best epochs: 0022 | Best acc: 00.619491\n",
      "Start epoch number: 24\n",
      "Epoch(s) 0024/0100 | acc: 0.63041 | loss: 0.692352263 | val_acc: 0.61464 | val_loss: 0.694012935 | Best epochs: 0024 | Best acc: 00.630409\n",
      "Start epoch number: 25\n",
      "Epoch(s) 0025/0100 | acc: 0.62694 | loss: 0.692729877 | val_acc: 0.62199 | val_loss: 0.693053998 | Best epochs: 0024 | Best acc: 00.630409\n",
      "Start epoch number: 26\n",
      "Epoch(s) 0026/0100 | acc: 0.62514 | loss: 0.692808135 | val_acc: 0.65653 | val_loss: 0.690059431 | Best epochs: 0024 | Best acc: 00.630409\n",
      "Start epoch number: 27\n",
      "Epoch(s) 0027/0100 | acc: 0.63335 | loss: 0.692039183 | val_acc: 0.63664 | val_loss: 0.691648314 | Best epochs: 0027 | Best acc: 00.633353\n",
      "Start epoch number: 28\n",
      "Epoch(s) 0028/0100 | acc: 0.62734 | loss: 0.692594929 | val_acc: 0.59794 | val_loss: 0.695589984 | Best epochs: 0027 | Best acc: 00.633353\n",
      "Start epoch number: 29\n",
      "Epoch(s) 0029/0100 | acc: 0.63199 | loss: 0.692118885 | val_acc: 0.65377 | val_loss: 0.690267873 | Best epochs: 0027 | Best acc: 00.633353\n",
      "Start epoch number: 30\n",
      "Epoch(s) 0030/0100 | acc: 0.63331 | loss: 0.692017455 | val_acc: 0.62327 | val_loss: 0.692899349 | Best epochs: 0027 | Best acc: 00.633353\n",
      "Start epoch number: 31\n",
      "Epoch(s) 0031/0100 | acc: 0.64054 | loss: 0.691360852 | val_acc: 0.64069 | val_loss: 0.691629156 | Best epochs: 0031 | Best acc: 00.640545\n",
      "Start epoch number: 32\n",
      "Epoch(s) 0032/0100 | acc: 0.63994 | loss: 0.691434643 | val_acc: 0.65694 | val_loss: 0.689745409 | Best epochs: 0031 | Best acc: 00.640545\n",
      "Start epoch number: 33\n",
      "Epoch(s) 0033/0100 | acc: 0.63474 | loss: 0.691874617 | val_acc: 0.65273 | val_loss: 0.690361090 | Best epochs: 0031 | Best acc: 00.640545\n",
      "Start epoch number: 34\n",
      "Epoch(s) 0034/0100 | acc: 0.64303 | loss: 0.691086015 | val_acc: 0.65959 | val_loss: 0.689714322 | Best epochs: 0034 | Best acc: 00.643029\n",
      "Start epoch number: 35\n",
      "Epoch(s) 0035/0100 | acc: 0.63413 | loss: 0.691967708 | val_acc: 0.57924 | val_loss: 0.697030423 | Best epochs: 0034 | Best acc: 00.643029\n",
      "Start epoch number: 36\n",
      "Epoch(s) 0036/0100 | acc: 0.64323 | loss: 0.691150503 | val_acc: 0.64398 | val_loss: 0.690910014 | Best epochs: 0036 | Best acc: 00.643229\n",
      "Start epoch number: 37\n",
      "Epoch(s) 0037/0100 | acc: 0.64696 | loss: 0.690740151 | val_acc: 0.68526 | val_loss: 0.687179121 | Best epochs: 0037 | Best acc: 00.646955\n",
      "Start epoch number: 38\n",
      "Epoch(s) 0038/0100 | acc: 0.63928 | loss: 0.691459685 | val_acc: 0.64701 | val_loss: 0.690812456 | Best epochs: 0037 | Best acc: 00.646955\n",
      "Start epoch number: 39\n",
      "Epoch(s) 0039/0100 | acc: 0.64056 | loss: 0.691337389 | val_acc: 0.62402 | val_loss: 0.692925995 | Best epochs: 0037 | Best acc: 00.646955\n",
      "Start epoch number: 40\n",
      "Epoch(s) 0040/0100 | acc: 0.64822 | loss: 0.690547485 | val_acc: 0.58653 | val_loss: 0.696113621 | Best epochs: 0040 | Best acc: 00.648217\n",
      "Start epoch number: 41\n",
      "Epoch(s) 0041/0100 | acc: 0.64677 | loss: 0.690756784 | val_acc: 0.66807 | val_loss: 0.688772490 | Best epochs: 0040 | Best acc: 00.648217\n",
      "Start epoch number: 42\n",
      "Epoch(s) 0042/0100 | acc: 0.64203 | loss: 0.691221596 | val_acc: 0.61074 | val_loss: 0.694035354 | Best epochs: 0040 | Best acc: 00.648217\n",
      "Start epoch number: 43\n",
      "Epoch(s) 0043/0100 | acc: 0.64820 | loss: 0.690611073 | val_acc: 0.67063 | val_loss: 0.688400023 | Best epochs: 0040 | Best acc: 00.648217\n",
      "Start epoch number: 44\n",
      "Epoch(s) 0044/0100 | acc: 0.63798 | loss: 0.691568033 | val_acc: 0.66956 | val_loss: 0.688625703 | Best epochs: 0040 | Best acc: 00.648217\n",
      "Start epoch number: 45\n",
      "Epoch(s) 0045/0100 | acc: 0.64617 | loss: 0.690777660 | val_acc: 0.63381 | val_loss: 0.692003548 | Best epochs: 0040 | Best acc: 00.648217\n",
      "Start epoch number: 46\n",
      "Epoch(s) 0046/0100 | acc: 0.65335 | loss: 0.690125132 | val_acc: 0.66715 | val_loss: 0.688726549 | Best epochs: 0046 | Best acc: 00.653345\n",
      "Start epoch number: 47\n",
      "Epoch(s) 0047/0100 | acc: 0.64569 | loss: 0.690772376 | val_acc: 0.69265 | val_loss: 0.686394441 | Best epochs: 0046 | Best acc: 00.653345\n",
      "Start epoch number: 48\n",
      "Epoch(s) 0048/0100 | acc: 0.66276 | loss: 0.689263109 | val_acc: 0.65729 | val_loss: 0.689608994 | Best epochs: 0048 | Best acc: 00.662760\n",
      "Start epoch number: 49\n",
      "Epoch(s) 0049/0100 | acc: 0.65331 | loss: 0.690063835 | val_acc: 0.66872 | val_loss: 0.688766338 | Best epochs: 0048 | Best acc: 00.662760\n",
      "Start epoch number: 50\n",
      "Epoch(s) 0050/0100 | acc: 0.65172 | loss: 0.690270226 | val_acc: 0.66439 | val_loss: 0.689270206 | Best epochs: 0048 | Best acc: 00.662760\n",
      "Start epoch number: 51\n",
      "Epoch(s) 0051/0100 | acc: 0.65727 | loss: 0.689769194 | val_acc: 0.63574 | val_loss: 0.691773372 | Best epochs: 0048 | Best acc: 00.662760\n",
      "Start epoch number: 52\n",
      "Epoch(s) 0052/0100 | acc: 0.65501 | loss: 0.689869726 | val_acc: 0.65786 | val_loss: 0.689497103 | Best epochs: 0048 | Best acc: 00.662760\n",
      "Start epoch number: 53\n",
      "Epoch(s) 0053/0100 | acc: 0.65312 | loss: 0.690098362 | val_acc: 0.64244 | val_loss: 0.691218120 | Best epochs: 0048 | Best acc: 00.662760\n",
      "Start epoch number: 54\n",
      "Epoch(s) 0054/0100 | acc: 0.65220 | loss: 0.690252193 | val_acc: 0.65835 | val_loss: 0.689642015 | Best epochs: 0048 | Best acc: 00.662760\n",
      "Start epoch number: 55\n",
      "Epoch(s) 0055/0100 | acc: 0.66042 | loss: 0.689500729 | val_acc: 0.64463 | val_loss: 0.690909646 | Best epochs: 0048 | Best acc: 00.662760\n",
      "Start epoch number: 56\n",
      "Epoch(s) 0056/0100 | acc: 0.65743 | loss: 0.689678503 | val_acc: 0.61403 | val_loss: 0.693613172 | Best epochs: 0048 | Best acc: 00.662760\n",
      "Start epoch number: 57\n",
      "Epoch(s) 0057/0100 | acc: 0.66621 | loss: 0.688860620 | val_acc: 0.67932 | val_loss: 0.687776901 | Best epochs: 0057 | Best acc: 00.666206\n",
      "Start epoch number: 58\n",
      "Epoch(s) 0058/0100 | acc: 0.66783 | loss: 0.688700621 | val_acc: 0.66288 | val_loss: 0.689104329 | Best epochs: 0058 | Best acc: 00.667829\n",
      "Start epoch number: 59\n",
      "Epoch(s) 0059/0100 | acc: 0.64998 | loss: 0.690384394 | val_acc: 0.69554 | val_loss: 0.686251476 | Best epochs: 0058 | Best acc: 00.667829\n",
      "Start epoch number: 60\n",
      "Epoch(s) 0060/0100 | acc: 0.66354 | loss: 0.689088500 | val_acc: 0.69143 | val_loss: 0.686583286 | Best epochs: 0058 | Best acc: 00.667829\n",
      "Start epoch number: 61\n",
      "Epoch(s) 0061/0100 | acc: 0.66538 | loss: 0.688976777 | val_acc: 0.66168 | val_loss: 0.689185838 | Best epochs: 0058 | Best acc: 00.667829\n",
      "Start epoch number: 62\n",
      "Epoch(s) 0062/0100 | acc: 0.65948 | loss: 0.689449048 | val_acc: 0.65688 | val_loss: 0.689830326 | Best epochs: 0058 | Best acc: 00.667829\n",
      "Start epoch number: 63\n",
      "Epoch(s) 0063/0100 | acc: 0.66563 | loss: 0.688911449 | val_acc: 0.66691 | val_loss: 0.688538869 | Best epochs: 0058 | Best acc: 00.667829\n",
      "Start epoch number: 64\n",
      "Epoch(s) 0064/0100 | acc: 0.65793 | loss: 0.689639393 | val_acc: 0.61721 | val_loss: 0.693459548 | Best epochs: 0058 | Best acc: 00.667829\n",
      "Start epoch number: 65\n",
      "Epoch(s) 0065/0100 | acc: 0.66426 | loss: 0.689047602 | val_acc: 0.68604 | val_loss: 0.686899851 | Best epochs: 0058 | Best acc: 00.667829\n",
      "Start epoch number: 66\n",
      "Epoch(s) 0066/0100 | acc: 0.66142 | loss: 0.689376445 | val_acc: 0.61633 | val_loss: 0.693481073 | Best epochs: 0058 | Best acc: 00.667829\n",
      "Start epoch number: 67\n",
      "Epoch(s) 0067/0100 | acc: 0.66897 | loss: 0.688495730 | val_acc: 0.57640 | val_loss: 0.697222650 | Best epochs: 0067 | Best acc: 00.668970\n",
      "Start epoch number: 68\n",
      "Epoch(s) 0068/0100 | acc: 0.66374 | loss: 0.689133807 | val_acc: 0.67700 | val_loss: 0.687826874 | Best epochs: 0067 | Best acc: 00.668970\n",
      "Start epoch number: 69\n",
      "Epoch(s) 0069/0100 | acc: 0.67778 | loss: 0.687789232 | val_acc: 0.68180 | val_loss: 0.687532127 | Best epochs: 0069 | Best acc: 00.677784\n",
      "Start epoch number: 70\n",
      "Epoch(s) 0070/0100 | acc: 0.66625 | loss: 0.688813501 | val_acc: 0.68014 | val_loss: 0.687376042 | Best epochs: 0069 | Best acc: 00.677784\n",
      "Start epoch number: 71\n",
      "Epoch(s) 0071/0100 | acc: 0.65703 | loss: 0.689676707 | val_acc: 0.64724 | val_loss: 0.690795134 | Best epochs: 0069 | Best acc: 00.677784\n",
      "Start epoch number: 72\n",
      "Epoch(s) 0072/0100 | acc: 0.66903 | loss: 0.688603423 | val_acc: 0.68549 | val_loss: 0.687161177 | Best epochs: 0069 | Best acc: 00.677784\n",
      "Start epoch number: 73\n",
      "Epoch(s) 0073/0100 | acc: 0.66981 | loss: 0.688512107 | val_acc: 0.65765 | val_loss: 0.689511394 | Best epochs: 0069 | Best acc: 00.677784\n",
      "Start epoch number: 74\n",
      "Epoch(s) 0074/0100 | acc: 0.67063 | loss: 0.688392248 | val_acc: 0.69639 | val_loss: 0.686056452 | Best epochs: 0069 | Best acc: 00.677784\n",
      "Start epoch number: 75\n",
      "Epoch(s) 0075/0100 | acc: 0.66733 | loss: 0.688751847 | val_acc: 0.66817 | val_loss: 0.688741970 | Best epochs: 0069 | Best acc: 00.677784\n",
      "Start epoch number: 76\n",
      "Epoch(s) 0076/0100 | acc: 0.67272 | loss: 0.688236896 | val_acc: 0.66941 | val_loss: 0.688553564 | Best epochs: 0069 | Best acc: 00.677784\n",
      "Start epoch number: 77\n",
      "Epoch(s) 0077/0100 | acc: 0.66935 | loss: 0.688534402 | val_acc: 0.68357 | val_loss: 0.687054647 | Best epochs: 0069 | Best acc: 00.677784\n",
      "Start epoch number: 78\n",
      "Epoch(s) 0078/0100 | acc: 0.67584 | loss: 0.687921117 | val_acc: 0.70372 | val_loss: 0.685281637 | Best epochs: 0069 | Best acc: 00.677784\n",
      "Start epoch number: 79\n",
      "Epoch(s) 0079/0100 | acc: 0.67458 | loss: 0.688050090 | val_acc: 0.69641 | val_loss: 0.686156000 | Best epochs: 0069 | Best acc: 00.677784\n",
      "Start epoch number: 80\n",
      "Epoch(s) 0080/0100 | acc: 0.66581 | loss: 0.688872343 | val_acc: 0.67519 | val_loss: 0.687893234 | Best epochs: 0069 | Best acc: 00.677784\n",
      "Start epoch number: 81\n",
      "Epoch(s) 0081/0100 | acc: 0.67378 | loss: 0.688047564 | val_acc: 0.60270 | val_loss: 0.694617607 | Best epochs: 0069 | Best acc: 00.677784\n",
      "Start epoch number: 82\n",
      "Epoch(s) 0082/0100 | acc: 0.67161 | loss: 0.688250817 | val_acc: 0.66974 | val_loss: 0.688688502 | Best epochs: 0069 | Best acc: 00.677784\n",
      "Start epoch number: 83\n",
      "Epoch(s) 0083/0100 | acc: 0.67378 | loss: 0.688116707 | val_acc: 0.67409 | val_loss: 0.688056481 | Best epochs: 0069 | Best acc: 00.677784\n",
      "Start epoch number: 84\n",
      "Epoch(s) 0084/0100 | acc: 0.66709 | loss: 0.688720925 | val_acc: 0.70445 | val_loss: 0.685297246 | Best epochs: 0069 | Best acc: 00.677784\n",
      "Start epoch number: 85\n",
      "Epoch(s) 0085/0100 | acc: 0.67504 | loss: 0.688025347 | val_acc: 0.69503 | val_loss: 0.686120403 | Best epochs: 0069 | Best acc: 00.677784\n",
      "Start epoch number: 86\n",
      "Epoch(s) 0086/0100 | acc: 0.67586 | loss: 0.687893932 | val_acc: 0.68827 | val_loss: 0.686973810 | Best epochs: 0069 | Best acc: 00.677784\n",
      "Start epoch number: 87\n",
      "Epoch(s) 0087/0100 | acc: 0.67496 | loss: 0.687956911 | val_acc: 0.68219 | val_loss: 0.687319999 | Best epochs: 0069 | Best acc: 00.677784\n",
      "Start epoch number: 88\n",
      "Epoch(s) 0088/0100 | acc: 0.66897 | loss: 0.688476036 | val_acc: 0.65432 | val_loss: 0.690073508 | Best epochs: 0069 | Best acc: 00.677784\n",
      "Start epoch number: 89\n",
      "Epoch(s) 0089/0100 | acc: 0.67167 | loss: 0.688260410 | val_acc: 0.65588 | val_loss: 0.689786692 | Best epochs: 0069 | Best acc: 00.677784\n",
      "Start epoch number: 90\n",
      "Epoch(s) 0090/0100 | acc: 0.67873 | loss: 0.687609654 | val_acc: 0.68038 | val_loss: 0.687506018 | Best epochs: 0090 | Best acc: 00.678726\n",
      "Start epoch number: 91\n",
      "Epoch(s) 0091/0100 | acc: 0.67183 | loss: 0.688278753 | val_acc: 0.67029 | val_loss: 0.688595700 | Best epochs: 0090 | Best acc: 00.678726\n",
      "Start epoch number: 92\n",
      "Epoch(s) 0092/0100 | acc: 0.67346 | loss: 0.688090508 | val_acc: 0.67336 | val_loss: 0.688151995 | Best epochs: 0090 | Best acc: 00.678726\n",
      "Start epoch number: 93\n",
      "Epoch(s) 0093/0100 | acc: 0.67796 | loss: 0.687746425 | val_acc: 0.68988 | val_loss: 0.686365907 | Best epochs: 0090 | Best acc: 00.678726\n",
      "Start epoch number: 94\n",
      "Epoch(s) 0094/0100 | acc: 0.68033 | loss: 0.687491836 | val_acc: 0.69527 | val_loss: 0.686052861 | Best epochs: 0094 | Best acc: 00.680329\n",
      "Start epoch number: 95\n",
      "Epoch(s) 0095/0100 | acc: 0.67923 | loss: 0.687619135 | val_acc: 0.68117 | val_loss: 0.687369230 | Best epochs: 0094 | Best acc: 00.680329\n",
      "Start epoch number: 96\n",
      "Epoch(s) 0096/0100 | acc: 0.67917 | loss: 0.687599103 | val_acc: 0.67053 | val_loss: 0.688475815 | Best epochs: 0094 | Best acc: 00.680329\n",
      "Start epoch number: 97\n",
      "Epoch(s) 0097/0100 | acc: 0.68313 | loss: 0.687215659 | val_acc: 0.66207 | val_loss: 0.689040974 | Best epochs: 0097 | Best acc: 00.683133\n",
      "Start epoch number: 98\n",
      "Epoch(s) 0098/0100 | acc: 0.67592 | loss: 0.687942404 | val_acc: 0.67942 | val_loss: 0.687596252 | Best epochs: 0097 | Best acc: 00.683133\n",
      "Start epoch number: 99\n",
      "Epoch(s) 0099/0100 | acc: 0.68057 | loss: 0.687401428 | val_acc: 0.68085 | val_loss: 0.687422693 | Best epochs: 0097 | Best acc: 00.683133\n",
      "Start epoch number: 100\n",
      "Epoch(s) 0100/0100 | acc: 0.67776 | loss: 0.687690575 | val_acc: 0.65625 | val_loss: 0.689649425 | Best epochs: 0097 | Best acc: 00.683133\n",
      "CNNs for None-gaussian-pertubed CIFAR10 = 0.82756\n",
      "ODEs for None-gaussian-pertubed CIFAR10 = 0.65664\n",
      "CNNs for 1e-07-gaussian-pertubed CIFAR10 = 0.81098\n",
      "ODEs for 1e-07-gaussian-pertubed CIFAR10 = 0.6824\n",
      "CNNs for 50.0-gaussian-pertubed CIFAR10 = 0.15236\n",
      "ODEs for 50.0-gaussian-pertubed CIFAR10 = 0.3066\n",
      "CNNs for 75.0-gaussian-pertubed CIFAR10 = 0.11128\n",
      "ODEs for 75.0-gaussian-pertubed CIFAR10 = 0.24058\n",
      "CNNs for 100.0-gaussian-pertubed CIFAR10 = 0.10348\n",
      "ODEs for 100.0-gaussian-pertubed CIFAR10 = 0.20744\n"
     ]
    }
   ],
   "source": [
    "for i in range(1):\n",
    "    cnn_model = main(ds_len_,ds_, ds_, device=device, model_type=\"cnn\", data_name=f\"mnist_origin\",batch_size=BATCH_SIZE, epochs=EPOCHS, train_num=TRAIN_NUM, valid_num=VALID_NUM, test_num=TEST_NUM, parallel=None) \n",
    "    ode_model = main(ds_len_,ds_, ds_, device=device, model_type=\"ode\", data_name=f\"mnist_origin\",batch_size=BATCH_SIZE, epochs=EPOCHS, train_num=TRAIN_NUM, valid_num=VALID_NUM, test_num=TEST_NUM, parallel=None) \n",
    "    for k,l in loaders:\n",
    "        if isinstance(cnn_model, nn.DataParallel): cnn_model = cnn_model.module\n",
    "        if isinstance(ode_model, nn.DataParallel): ode_model = ode_model.module\n",
    "        _, cnn_acc = cnn_model.evaluate(l) \n",
    "        _, ode_acc = ode_model.evaluate(l) \n",
    "        \n",
    "        print(f\"CNNs for {k}-gaussian-pertubed CIFAR10 = {cnn_acc}\")\n",
    "        print(f\"ODEs for {k}-gaussian-pertubed CIFAR10 = {ode_acc}\")\n",
    "        \n",
    "\n",
    "        evaluation[\"ode\"][k].append(ode_acc)\n",
    "        evaluation[\"cnn\"][k].append(cnn_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811bb408-4a42-4647-8bc2-6e71eaf29b3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

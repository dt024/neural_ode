{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0740cb7d",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Necessary\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "from torchdiffeq import odeint_adjoint as odeint\n",
    "# from jupyterthemes import jtplot\n",
    "from utils import *\n",
    "# jtplot.style(theme=\"chesterish\")\n",
    " # CONSTANT \n",
    "device = \"cpu\"\n",
    "EPOCHS=1\n",
    "BATCH_SIZE=32\n",
    "IMG_SIZE=(32,32,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75bd4ff5",
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/administrator/anaconda3/envs/neural_ode/lib/python3.9/site-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "DIR = \"./data/mnist/\"\n",
    "MNIST = torchvision.datasets.MNIST(DIR,\n",
    "                                   train=True,\n",
    "                                   transform=None,\n",
    "                                   target_transform=None, download=False)\n",
    "\n",
    "\n",
    "#ds_len_, normal_ds_, pertubed_ds_ = preprocess_data(MNIST)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "246727a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, optimizer, train_loader, val_loader,loss_fn, epochs=100):\n",
    "    print(model.eval())\n",
    "    print(f\"Numbers of parameters in model: {sum(p.numel() for p in model.parameters() if p.requires_grad)}\")\n",
    "    history = {\"loss\": [], \"acc\": [], \"val_loss\": [], \"val_acc\": []}\n",
    "    for epoch_id in tqdm(range(epochs)):\n",
    "        total = 0\n",
    "        correct = 0\n",
    "        running_loss = 0\n",
    "        print(f\"Start epoch number: {epoch_id + 1}\")\n",
    "        for batch_id, data in enumerate(train_loader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            #print(f\"Start batch number: {batch_id + 1} in epoch number: {epoch_id + 1}\")\n",
    "            inputs, labels = data\n",
    "            #print(f\"Get data done\")\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            #print(f\"Reset the optimizer backward, grad to 0\") \n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs)\n",
    "            #print(f\"forward data through model\")\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            #print(f\"Get predicted class\")\n",
    "            _, correct_labels = torch.max(labels, 1)\n",
    "            #print(f\"Get label class\")\n",
    "            #print(labels)\n",
    "            total += labels.size(0)\n",
    "            correct += correct += (predicted == correct_labels).sum().item()\n",
    "            #print(\"Calculate the number of correct predictions\")\n",
    "            #print(labels.shape, outputs.shape)\n",
    "            loss = loss_fn(outputs.float(), labels.float())\n",
    "            loss.backward()\n",
    "            #print(\"Backward loss\")\n",
    "            optimizer.step()\n",
    "            #print(\"Step\")\n",
    "            running_loss += loss.item() \n",
    "            #print(f\"End batch number: {batch_id + 1} in epoch number {epoch_id + 1}\")\n",
    "        acc = round(correct/total * 1.0, 2)\n",
    "        #print(\"Accuracy was calculated\")\n",
    "        history[\"acc\"].append(acc)\n",
    "        history[\"loss\"].append(running_loss)\n",
    "        print(\"Before evaluate\")\n",
    "        val_loss, val_acc = model.evaluate(val_loader)\n",
    "        print(\"After evaluation\")\n",
    "        history[\"val_loss\"].append(val_loss)\n",
    "        history[\"val_acc\"].append(val_acc)\n",
    "        print(f\"Epoch(s) {epoch_id + 1} | loss: {loss} | acc: {acc} | val_loss: {val_loss} | val_acc: {val_acc}\")\n",
    "    return history\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def main(ds_len, ds, name = \"mnist_50\",batch_size=32,epochs=100, lr=1e-3,data_dis=[8000,2000,50000], device=\"cpu\", result_dir=\"./result\"):\n",
    "    print(f\"Number of train: {data_dis[0]}\\nNumber of validation: {data_dis[1]}\")\n",
    "    train_set, val_set, _ = torch.utils.data.random_split(ds,data_dis)\n",
    "    #print(type(train_set))\n",
    "    assert isinstance(train_set,torch.utils.data.Dataset)\n",
    "    train_loader = DataLoader(train_set, shuffle=True, batch_size=batch_size)\n",
    "    val_loader = DataLoader(val_set, shuffle=True, batch_size=data_dis[1])\n",
    "    loss_fn = torch.nn.functional.binary_cross_entropy_with_logits\n",
    "    ode_func = ODEBlock().to(device)\n",
    "    ode_model = ODENet(ode_func, device=device).to(device)\n",
    "    ode_optimizer = torch.optim.Adam(ode_model.parameters(), lr=lr)\n",
    "    cnn_model = Network().to(device)\n",
    "    cnn_optimizer = torch.optim.Adam(cnn_model.parameters(), lr=lr)\n",
    "    cnn_his = train_model(cnn_model, \n",
    "                         cnn_optimizer,\n",
    "                         train_loader, val_loader, loss_fn=loss_fn,epochs=epochs)\n",
    "    ode_his = train_model(ode_model,\n",
    "                          ode_optimizer,\n",
    "                          train_loader, val_loader, loss_fn=loss_fn, epochs=epochs)\n",
    "    save_result(cnn_his,model_name=\"cnn\",ds_name=name, result_dir=result_dir)\n",
    "    save_result(ode_his,model_name=\"ode\",ds_name=name, result_dir=result_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a07757bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AxesImage(54,36;334.8x217.44)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(plt.imshow(np.array(MNIST[300][0]) / 255.0, cmap=\"gray\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69df20aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ds_len, _ds = preprocess_data(MNIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a72b5b7",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_8994/3643631284.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"50.0\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "print(_ds[\"50.0\"][1].shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
